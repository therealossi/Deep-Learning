{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 6 - CNN - Backpropagation: Convolution\n",
    "\n",
    "Dieses Notebook thematisiert die Backpropagation durch eine Convolution in Convolutional Neural Networks (CNNs).\n",
    "\n",
    "Ziel ist es, die Funktionsweise der Convolution während der Backpropagation genau zu analysieren und nachzuimplementieren.\n",
    "\n",
    "<font color=\"#aa0000\">**Hinweis:**</font>\n",
    "Dieses Notebook enthält Praktikumsaufgaben ([P6.1](#praktikum), [P6.2](#praktikum2), [P6.3](#praktikum3)). Erweitern Sie das Notebook geeignet und speichern Sie das ausgeführte Notebook erneut ab (File &rarr; Download as &rarr; Notebook). Reichen Sie abschließend das heruntergeladene Notebook im zugehörigen [Moodle-Kurs](https://moodle2.tu-ilmenau.de/course/view.php?id=4366) ein.\n",
    "\n",
    "**Die Einreichungsfrist finden Sie im Moodle-Kurs.**\n",
    "\n",
    "### Inhaltsverzeichnis\n",
    "- [(f) Implementierung der Convolution mit NumPy](#f)\n",
    "    - [Berechnung der Größe der Output Feature Maps](#output_shape)\n",
    "    - [Berechnung der Convolution](#funktion_conv)\n",
    "    - [Berechnung der Gradienten](#gradienten)\n",
    "- [Praktikumsaufgabe P6.1 zur Strided Convolution](#praktikum)\n",
    "- [Praktikumsaufgabe P6.2 zur Convolution mit Dilation & Padding](#praktikum2)\n",
    "- [Praktikumsaufgabe P6.3 zur Convolution mit 1x1 Filtern & Gruppen ](#praktikum3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 5px\">\n",
    "\n",
    "### Vorbereitung\n",
    "Wichtige Ergebnisse können während der Bearbeitung überprüft werden. Grundvoraussetzung hierfür ist, dass Sie das Paket `tui-dl4cv` <font color=\"#aa0000\">installieren bzw. aktualisieren</font> und anschließend importieren.\n",
    "\n",
    "Für die Installation stehen Ihnen zwei mögliche Wege zur Verfügung.\n",
    "\n",
    "**(1) Installation direkt in diesem Notebook:**\n",
    "Führen Sie den nachfolgenden Code-Block aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically install package for '/usr/bin/python3'\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://2022ws:****@nikrgl.informatik.tu-ilmenau.de/api/v4/projects/1730/packages/pypi/simple\n",
      "Requirement already satisfied: tui-dl4cv in /home/marius/.local/lib/python3.10/site-packages (0.3.1)\n",
      "\u001b[33mDEPRECATION: The HTML index page being used (https://nikrgl.informatik.tu-ilmenau.de/api/v4/projects/1730/packages/pypi/simple/tui-dl4cv/) is not a proper HTML 5 document. This is in violation of PEP 503 which requires these pages to be well-formed HTML 5 documents. Please reach out to the owners of this index page, and ask them to update this index page to a valid HTML 5 document. pip 22.2 will enforce this behaviour change. Discussion can be found at https://github.com/pypa/pip/issues/10825\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pytorchcv in /home/marius/.local/lib/python3.10/site-packages (from tui-dl4cv) (0.0.67)\n",
      "Requirement already satisfied: tqdm in /home/marius/.local/lib/python3.10/site-packages (from tui-dl4cv) (4.64.1)\n",
      "Requirement already satisfied: jupyter in /home/marius/.local/lib/python3.10/site-packages (from tui-dl4cv) (1.0.0)\n",
      "Requirement already satisfied: matplotlib in /home/marius/.local/lib/python3.10/site-packages (from tui-dl4cv) (3.6.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from tui-dl4cv) (2.25.1)\n",
      "Requirement already satisfied: seaborn in /home/marius/.local/lib/python3.10/site-packages (from tui-dl4cv) (0.12.1)\n",
      "Requirement already satisfied: pytorch-lightning>=1.5.3 in /home/marius/.local/lib/python3.10/site-packages (from tui-dl4cv) (1.7.7)\n",
      "Requirement already satisfied: torchmetrics>=0.6.0torchvision in /home/marius/.local/lib/python3.10/site-packages (from tui-dl4cv) (0.10.0)\n",
      "Requirement already satisfied: gdown in /home/marius/.local/lib/python3.10/site-packages (from tui-dl4cv) (4.5.3)\n",
      "Requirement already satisfied: torchinfo in /home/marius/.local/lib/python3.10/site-packages (from tui-dl4cv) (1.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/marius/.local/lib/python3.10/site-packages (from pytorch-lightning>=1.5.3->tui-dl4cv) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/marius/.local/lib/python3.10/site-packages (from pytorch-lightning>=1.5.3->tui-dl4cv) (1.23.3)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /home/marius/.local/lib/python3.10/site-packages (from pytorch-lightning>=1.5.3->tui-dl4cv) (2022.8.2)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /home/marius/.local/lib/python3.10/site-packages (from pytorch-lightning>=1.5.3->tui-dl4cv) (0.3.2)\n",
      "Requirement already satisfied: torch>=1.9.* in /home/marius/.local/lib/python3.10/site-packages (from pytorch-lightning>=1.5.3->tui-dl4cv) (1.12.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/marius/.local/lib/python3.10/site-packages (from pytorch-lightning>=1.5.3->tui-dl4cv) (21.3)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/lib/python3/dist-packages (from pytorch-lightning>=1.5.3->tui-dl4cv) (5.4.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /home/marius/.local/lib/python3.10/site-packages (from pytorch-lightning>=1.5.3->tui-dl4cv) (2.10.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/marius/.local/lib/python3.10/site-packages (from gdown->tui-dl4cv) (4.11.1)\n",
      "Requirement already satisfied: filelock in /home/marius/.local/lib/python3.10/site-packages (from gdown->tui-dl4cv) (3.8.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown->tui-dl4cv) (1.16.0)\n",
      "Requirement already satisfied: ipykernel in /home/marius/.local/lib/python3.10/site-packages (from jupyter->tui-dl4cv) (6.17.0)\n",
      "Requirement already satisfied: jupyter-console in /home/marius/.local/lib/python3.10/site-packages (from jupyter->tui-dl4cv) (6.4.4)\n",
      "Requirement already satisfied: nbconvert in /home/marius/.local/lib/python3.10/site-packages (from jupyter->tui-dl4cv) (7.2.3)\n",
      "Requirement already satisfied: ipywidgets in /home/marius/.local/lib/python3.10/site-packages (from jupyter->tui-dl4cv) (8.0.2)\n",
      "Requirement already satisfied: qtconsole in /home/marius/.local/lib/python3.10/site-packages (from jupyter->tui-dl4cv) (5.4.0)\n",
      "Requirement already satisfied: notebook in /home/marius/.local/lib/python3.10/site-packages (from jupyter->tui-dl4cv) (6.5.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib->tui-dl4cv) (2.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/marius/.local/lib/python3.10/site-packages (from matplotlib->tui-dl4cv) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/marius/.local/lib/python3.10/site-packages (from matplotlib->tui-dl4cv) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/marius/.local/lib/python3.10/site-packages (from matplotlib->tui-dl4cv) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/marius/.local/lib/python3.10/site-packages (from matplotlib->tui-dl4cv) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/marius/.local/lib/python3.10/site-packages (from matplotlib->tui-dl4cv) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib->tui-dl4cv) (9.0.1)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/marius/.local/lib/python3.10/site-packages (from seaborn->tui-dl4cv) (1.5.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/marius/.local/lib/python3.10/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.5.3->tui-dl4cv) (3.8.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=0.25->seaborn->tui-dl4cv) (2022.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/marius/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (2.12.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (59.6.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/marius/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/marius/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/marius/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/marius/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (1.49.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/marius/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (1.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/marius/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (0.6.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/lib/python3/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (3.12.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/marius/.local/lib/python3.10/site-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (3.4.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/marius/.local/lib/python3.10/site-packages (from beautifulsoup4->gdown->tui-dl4cv) (2.3.2.post1)\n",
      "Requirement already satisfied: psutil in /home/marius/.local/lib/python3.10/site-packages (from ipykernel->jupyter->tui-dl4cv) (5.9.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/marius/.local/lib/python3.10/site-packages (from ipykernel->jupyter->tui-dl4cv) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/marius/.local/lib/python3.10/site-packages (from ipykernel->jupyter->tui-dl4cv) (6.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/marius/.local/lib/python3.10/site-packages (from ipykernel->jupyter->tui-dl4cv) (7.4.4)\n",
      "Requirement already satisfied: debugpy>=1.0 in /home/marius/.local/lib/python3.10/site-packages (from ipykernel->jupyter->tui-dl4cv) (1.6.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/marius/.local/lib/python3.10/site-packages (from ipykernel->jupyter->tui-dl4cv) (0.1.6)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /home/marius/.local/lib/python3.10/site-packages (from ipykernel->jupyter->tui-dl4cv) (5.5.0)\n",
      "Requirement already satisfied: nest-asyncio in /home/marius/.local/lib/python3.10/site-packages (from ipykernel->jupyter->tui-dl4cv) (1.5.6)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/marius/.local/lib/python3.10/site-packages (from ipykernel->jupyter->tui-dl4cv) (8.6.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /home/marius/.local/lib/python3.10/site-packages (from ipywidgets->jupyter->tui-dl4cv) (3.0.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /home/marius/.local/lib/python3.10/site-packages (from ipywidgets->jupyter->tui-dl4cv) (4.0.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/marius/.local/lib/python3.10/site-packages (from jupyter-console->jupyter->tui-dl4cv) (3.0.32)\n",
      "Requirement already satisfied: pygments in /usr/lib/python3/dist-packages (from jupyter-console->jupyter->tui-dl4cv) (2.11.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/marius/.local/lib/python3.10/site-packages (from nbconvert->jupyter->tui-dl4cv) (1.5.0)\n",
      "Requirement already satisfied: defusedxml in /home/marius/.local/lib/python3.10/site-packages (from nbconvert->jupyter->tui-dl4cv) (0.7.1)\n",
      "Requirement already satisfied: tinycss2 in /home/marius/.local/lib/python3.10/site-packages (from nbconvert->jupyter->tui-dl4cv) (1.2.1)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /home/marius/.local/lib/python3.10/site-packages (from nbconvert->jupyter->tui-dl4cv) (2.0.4)\n",
      "Requirement already satisfied: bleach in /home/marius/.local/lib/python3.10/site-packages (from nbconvert->jupyter->tui-dl4cv) (5.0.1)\n",
      "Requirement already satisfied: nbformat>=5.1 in /home/marius/.local/lib/python3.10/site-packages (from nbconvert->jupyter->tui-dl4cv) (5.7.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/marius/.local/lib/python3.10/site-packages (from nbconvert->jupyter->tui-dl4cv) (0.7.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/marius/.local/lib/python3.10/site-packages (from nbconvert->jupyter->tui-dl4cv) (0.2.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /home/marius/.local/lib/python3.10/site-packages (from nbconvert->jupyter->tui-dl4cv) (2.1.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in /home/marius/.local/lib/python3.10/site-packages (from nbconvert->jupyter->tui-dl4cv) (3.1.2)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /home/marius/.local/lib/python3.10/site-packages (from nbconvert->jupyter->tui-dl4cv) (4.11.2)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /home/marius/.local/lib/python3.10/site-packages (from notebook->jupyter->tui-dl4cv) (0.4.8)\n",
      "Requirement already satisfied: argon2-cffi in /home/marius/.local/lib/python3.10/site-packages (from notebook->jupyter->tui-dl4cv) (21.3.0)\n",
      "Requirement already satisfied: prometheus-client in /home/marius/.local/lib/python3.10/site-packages (from notebook->jupyter->tui-dl4cv) (0.15.0)\n",
      "Requirement already satisfied: ipython-genutils in /home/marius/.local/lib/python3.10/site-packages (from notebook->jupyter->tui-dl4cv) (0.2.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/marius/.local/lib/python3.10/site-packages (from notebook->jupyter->tui-dl4cv) (0.17.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/marius/.local/lib/python3.10/site-packages (from notebook->jupyter->tui-dl4cv) (1.8.0)\n",
      "Requirement already satisfied: qtpy>=2.0.1 in /home/marius/.local/lib/python3.10/site-packages (from qtconsole->jupyter->tui-dl4cv) (2.2.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/marius/.local/lib/python3.10/site-packages (from requests->tui-dl4cv) (1.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/marius/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.5.3->tui-dl4cv) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/marius/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.5.3->tui-dl4cv) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/marius/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.5.3->tui-dl4cv) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/marius/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.5.3->tui-dl4cv) (1.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/marius/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.5.3->tui-dl4cv) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/marius/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.5.3->tui-dl4cv) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/marius/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.5.3->tui-dl4cv) (2.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/marius/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/marius/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/marius/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/marius/.local/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (1.3.1)\n",
      "Requirement already satisfied: decorator in /home/marius/.local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->tui-dl4cv) (5.1.1)\n",
      "Requirement already satisfied: backcall in /home/marius/.local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->tui-dl4cv) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/marius/.local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->tui-dl4cv) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /home/marius/.local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->tui-dl4cv) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->tui-dl4cv) (4.8.0)\n",
      "Requirement already satisfied: stack-data in /home/marius/.local/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter->tui-dl4cv) (0.6.0)\n",
      "Requirement already satisfied: entrypoints in /home/marius/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->tui-dl4cv) (0.4)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /home/marius/.local/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter->tui-dl4cv) (0.2.2)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /home/marius/.local/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter->tui-dl4cv) (1.21.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/marius/.local/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert->jupyter->tui-dl4cv) (4.17.0)\n",
      "Requirement already satisfied: fastjsonschema in /home/marius/.local/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert->jupyter->tui-dl4cv) (2.16.2)\n",
      "Requirement already satisfied: wcwidth in /home/marius/.local/lib/python3.10/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->tui-dl4cv) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess in /usr/lib/python3/dist-packages (from terminado>=0.8.3->notebook->jupyter->tui-dl4cv) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/marius/.local/lib/python3.10/site-packages (from argon2-cffi->notebook->jupyter->tui-dl4cv) (21.2.0)\n",
      "Requirement already satisfied: webencodings in /home/marius/.local/lib/python3.10/site-packages (from bleach->nbconvert->jupyter->tui-dl4cv) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/marius/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->tui-dl4cv) (0.8.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/marius/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->tui-dl4cv) (0.19.2)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /home/marius/.local/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->tui-dl4cv) (3.6.2)\n",
      "Requirement already satisfied: websocket-client in /home/marius/.local/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->tui-dl4cv) (1.4.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/marius/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning>=1.5.3->tui-dl4cv) (3.2.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.5.3->tui-dl4cv) (3.3)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/marius/.local/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->tui-dl4cv) (1.15.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/marius/.local/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->tui-dl4cv) (2.1.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/marius/.local/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->tui-dl4cv) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /home/marius/.local/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->tui-dl4cv) (0.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/marius/.local/lib/python3.10/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->tui-dl4cv) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /home/marius/.local/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->tui-dl4cv) (2.21)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(f\"Automatically install package for '{sys.executable}'\")\n",
    "!{sys.executable} -m pip install tui-dl4cv \\\n",
    "    --extra-index-url \"https://2022ws:xXCgQHZxxeNYchgryN7e@nikrgl.informatik.tu-ilmenau.de/api/v4/projects/1730/packages/pypi/simple\" \\\n",
    "    --no-cache --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ODER\n",
    "\n",
    "**(2) Manuelle Installation über die Konsole:**\n",
    "Öffnen Sie eine Konsole (\"Anaconda Prompt\" unter Windows) und führen Sie folgenden Befehl aus:\n",
    "```text\n",
    "pip install tui-dl4cv --extra-index-url \"https://2022ws:xXCgQHZxxeNYchgryN7e@nikrgl.informatik.tu-ilmenau.de/api/v4/projects/1730/packages/pypi/simple\" --no-cache --upgrade\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Führen Sie abschließend folgenden Code-Block aus, um das Paket verwenden zu können.**\n",
    "Während der Bearbeitung können Sie nun Ihre Ergebnisse mithilfe der Funktion `interactive_check` überprüfen. Die Funktionsaufrufe sind bereits an den entsprechenden Stellen im Notebook enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tui_dl4cv.cnn\n",
    "\n",
    "# noetige Erweiterung, damit Variablen aus diesem Notebook automatisch ueberprueft werden koennen\n",
    "def interactive_check(name, **kwargs):\n",
    "    tui_dl4cv.cnn.interactive_check(name, globals(), **kwargs)\n",
    "\n",
    "from tui_dl4cv.cnn import print_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 5px\">\n",
    "\n",
    "<a name=\"f\"></a>\n",
    "### (f) Implementieren Sie die Convolution mithilfe von NumPy und reproduzieren Sie die Ergebnisse der Forward Propagation und der Backpropagation für die letzten beiden Convolutions aus Teilaufgabe (a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Pakete importieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"output_shape\"></a>\n",
    "**Zunächst muss eine Funktion implementiert werden, mit deren Hilfe die Größe der Output Feature Maps in Abhängigkeit der verwendeten Parameter der Convolution berechnet werden kann.**\n",
    "Das Wissen über die Größe der Output Feature Maps ermöglicht es, später ausreichend Speicher für das Ergebnis der Convolution zu allokieren. Zudem gibt sie Aufschluss darüber, wie viele Aufpunkte in der Convolution berechnet werden müssen.\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Die Formel zur Berechnung der Größe der Output Feature Maps in Abhängigkeit aller behandelten Parameter der Convolution wird in der Vorlesung und der Übung thematisiert.\n",
    "</div>\n",
    "\n",
    "*Implementierung:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_shape(input_shape, kernel_size, stride=(1, 1), padding=(0, 0), dilation=(1, 1)):\n",
    "    assert all(isinstance(p, tuple) for p in locals().values()), \"Alle Parameter als Tuple erwartet\"\n",
    "\n",
    "    # Hoehe `h_out` bestimmen (erstes Element in den Tuplen)\n",
    "    h_out = (input_shape[0] + 2* padding[0] - dilation[0]*(kernel_size[0]-1)-1) / stride[0] +1 # bitte Code ergaenzen <---------------- [Luecke (1)]\n",
    "\n",
    "    # Breite `w_out` bestimmen (zweites Element in den Tuplen)\n",
    "    w_out = (input_shape[1] + 2* padding[1] - dilation[1]*(kernel_size[1]-1)-1) / stride[1] +1 # bitte Code ergaenzen <---------------- [Luecke (2)]\n",
    "\n",
    "    # Ergebnisse durch Cast zu Int abrunden und zurueckgeben\n",
    "    return int(h_out), int(w_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Überprüfung:*\n",
    "\n",
    "Zur Überprüfung können die Größen der Output Feature Maps in der Aufgabenstellung berechnet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape Conv1:\n",
      " (4, 4)\n",
      "Output Shape Conv2:\n",
      " (3, 3)\n",
      "Output Shape Conv3:\n",
      " (1, 1)\n",
      "Output Shape:\n",
      " (4, 9)\n"
     ]
    }
   ],
   "source": [
    "# Convolution 1\n",
    "print(\"Output Shape Conv1:\\n\",\n",
    "      get_output_shape(input_shape=(8, 8), kernel_size=(2, 2), stride=(2,2)))\n",
    "\n",
    "# Convolution 2\n",
    "print(\"Output Shape Conv2:\\n\",\n",
    "      get_output_shape(input_shape=(4, 4), kernel_size=(2, 2)))\n",
    "\n",
    "# Convolution 3\n",
    "print(\"Output Shape Conv3:\\n\",\n",
    "      get_output_shape(input_shape=(3, 3), kernel_size=(3, 3)))\n",
    "\n",
    "# zusaetzlich komplexer Fall mit Stride, Padding und Dilation:\n",
    "print(\"Output Shape:\\n\",\n",
    "      get_output_shape(input_shape=(10, 11),\n",
    "                       kernel_size=(3, 4),\n",
    "                       stride=(2, 1),\n",
    "                       padding=(0, 2),\n",
    "                       dilation=(1, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "<code style=\"padding: 0px\">\n",
    "Output Shape Conv1:\n",
    " (4, 4)\n",
    "Output Shape Conv2:\n",
    " (3, 3)\n",
    "Output Shape Conv3:\n",
    " (1, 1)\n",
    "Output Shape:\n",
    " (4, 9)\n",
    "</code>\n",
    "</details>\n",
    "\n",
    "---\n",
    "<a name=\"funktion_conv\"></a>\n",
    "**Anschließend kann eine Funktion zur Berechnung der Convolution implementiert werden.**\n",
    "\n",
    "Beachten Sie:\n",
    "- Es handelt sich bei den betrachteten beiden Convolutions um Standard Convolutions, daher sollen zunächst keine zusätzlichen Parameter einbezogen werden.\n",
    "- Der Input Tensor ist 4-dimensional und enthält eine zusätzliche Achse für die Beispiele im Batch.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Folgende Funktionen könnten für die Vervollständigung der Lücken hilfreich sein:\n",
    "<ul style=\"margin-bottom: 0px; margin-top: 0px\">\n",
    "    <li><code style=\"background-color: #FAEAEA; padding: 0px\">scipy.signal.correlate2d</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.correlate2d.html\" target=\"_blank\">SciPy-Dokumentation</a><br>\n",
    "        Diese Funktion ist für zweidimensionale Inputs (height, width) und für eine Verwendung ohne Bias konzipiert. Es gibt zudem auch eine Funktion scipy.signal.convolve2d,\n",
    "welche passender klingt, die Filter allerdings vor der Anwendung um 180° dreht. Im nachfolgenden Code-Block wird die Faltungsoperation händisch realisiert.\n",
    "    </li>\n",
    "    <li><code style=\"background-color: #FAEAEA; padding: 0px\">np.zeros</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.zeros.html\" target=\"_blank\">NumPy-Dokumentation</a>\n",
    "    </li>\n",
    "    <li><code style=\"background-color: #FAEAEA; padding: 0px\">np.sum</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.sum.html\" target=\"_blank\">NumPy-Dokumentation</a>\n",
    "    </li>\n",
    "    <li><code style=\"background-color: #FAEAEA; padding: 0px\">slice</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://docs.python.org/3/library/functions.html#slice\" target=\"_blank\">Python-Dokumentation</a>\n",
    "        </li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "*Implementierung:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_tensor, filter_tensor, bias_tensor=None, stride=(1, 1), padding=(0, 0), dilation=(1, 1), groups=1):\n",
    "    # ueberpruefen, ob gueltige Parameter uebergeben wurden, andernfalls nicht implementiert als Fehler zurueckgeben\n",
    "    assert stride == (1, 1), \"Not implemented\"\n",
    "    assert padding == (0, 0), \"Not implemented\"\n",
    "    assert dilation == (1, 1), \"Not implemented\"\n",
    "    assert groups == 1, \"Not implemented\"\n",
    "\n",
    "    # Groessen aus Groesse des Input Tensors extrahieren\n",
    "    n_examples, n_channels_in, h_in, w_in = input_tensor.shape\n",
    "\n",
    "    # Groessen aus Groesse des Filter Tensors extrahieren\n",
    "    n_channels_out, n_channels_in_kernel, h_kernel, w_kernel = filter_tensor.shape\n",
    "\n",
    "    # kleiner Check: sofern keine Grouped Convolution oder Depthwise Convolution sind beide identisch\n",
    "    assert n_channels_in == n_channels_in_kernel, \"Not implemented\"\n",
    "\n",
    "    # Groesse `(h_out, w_out)` der Output Feature Maps bestimmen\n",
    "    h_out, w_out = get_output_shape(input_shape=(h_in,w_in), kernel_size=(h_kernel,w_kernel), \n",
    "                                    stride=stride, padding=padding, dilation=dilation) # bitte Code ergaenzen <---------------- [Luecke (3)]\n",
    "\n",
    "    # leeren Output Tensor allokieren\n",
    "    output_tensor = np.zeros((n_examples, n_channels_out, h_out, w_out), dtype=np.float32)\n",
    "\n",
    "    # Output berechnen\n",
    "    for ex in range(0, n_examples):\n",
    "        # fuer jedes Beispiel im Batch\n",
    "\n",
    "        for ch_out in range(0, n_channels_out):\n",
    "            # fuer jeden Output Channel\n",
    "\n",
    "            for i in range(0, h_out):\n",
    "                # fuer jede y-Position i der Hoehe der Output Feature Maps\n",
    "\n",
    "                for j in range(0, w_out):\n",
    "                    # fuer jede x-Position j der Breite der Output Feature Maps\n",
    "\n",
    "                    # Slices `vertical` und `horizontal` fuer relevanten Teil in den Input Feature Maps\n",
    "                    # ausgehend von aktueller Position i und j bestimmen\n",
    "                    vertical = slice(i,i+h_kernel) # bitte Code ergaenzen <---------------- [Luecke (4)]\n",
    "                    horizontal = slice(j,j+w_kernel)# bitte Code ergaenzen <---------------- [Luecke (5)]\n",
    "\n",
    "                    # Ergebnisse fuer jeden Input Channel akkumulieren\n",
    "                    for ch_in in range(0, n_channels_in):\n",
    "                        # für jeden Input Channel\n",
    "\n",
    "                        # Teil der Input Feature Map `input_window` aus Input Tensor extrahieren\n",
    "                        input_window = input_tensor[ex, ch_in, vertical, horizontal] # bitte Code ergaenzen <---------------- [Luecke (6)]\n",
    "\n",
    "                        # 2D Filter `weight` aus Filter Tensor extrahieren\n",
    "                        weight = filter_tensor[ch_out,ch_in,:,:] # bitte Code ergaenzen <---------------- [Luecke (7)]\n",
    "\n",
    "                        # elementweise Multiplikation des Fenster mit Filtergewichten\n",
    "                        # und anschliessende Summation\n",
    "                        result = np.sum(input_window * weight, axis=None)\n",
    "\n",
    "                        # Ergebnis zum bisherigen Ergebnis hinzuaddieren\n",
    "                        output_tensor[ex, ch_out, i, j] += result\n",
    "\n",
    "                    # nach der Faltung zur Feature Map gehoerendes Bias Gewicht addieren\n",
    "                    if bias_tensor is not None:\n",
    "                        output_tensor[ex,ch_out,i,j]+= bias_tensor[ch_out] # bitte Code ergaenzen <---------------- [Luecke (8)]\n",
    "\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Überprüfung:*\n",
    "\n",
    "Zur Überprüfung können die Output Volumes aus der Aufgabenstellung berechnet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o_2:\n",
      "[[[[ 6.  3.  7.]\n",
      "   [-7.  0.  3.]\n",
      "   [ 9.  3. -2.]]]]\n",
      "o_3:\n",
      "[[[[0.5]]]]\n"
     ]
    }
   ],
   "source": [
    "# Netzwerkeingabe als Tensor mit Groesse 1x1x8x8 definieren\n",
    "o_0 = np.array([[[[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                  [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0],\n",
    "                  [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0],\n",
    "                  [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
    "                  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0],\n",
    "                  [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0],\n",
    "                  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                  [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]]]], dtype='float32')\n",
    "\n",
    "# Gewichte Convolution 1\n",
    "# Filter\n",
    "w_1 = np.array([[[[2.0, -2.0],\n",
    "                  [1.0, -1.0]]]], dtype='float32')\n",
    "# Bias\n",
    "b_1 = np.array([0], dtype='float32')\n",
    "\n",
    "# Output Tensor nach der ersten Convolution mit Groesse 1x1x4x4 definieren\n",
    "o_1 = np.array([[[[1.0, 2.0, 0.0, -1.0],\n",
    "                  [3.0, 2.0, 1.0, 1.0],\n",
    "                  [-2.0, 0.0, 1.0, 1.0],\n",
    "                  [0.0, 1.0, 0.0, -1.0]]]], dtype='float32')\n",
    "\n",
    "# Gewichte Convolution 2\n",
    "# Filter\n",
    "w_2 = np.array([[[[-2.0, -1.0],\n",
    "                  [1.0, 2.0]]]], dtype='float32')\n",
    "# Bias\n",
    "b_2 = np.array([3], dtype='float32')\n",
    "\n",
    "\n",
    "# Gewichte Convolution 3\n",
    "# Filter\n",
    "w_3 = np.array([[[[1.0, 1.0, 2.0],\n",
    "                  [3.0, 0.0, 1.0],\n",
    "                  [-1.0, 1.0, -2.0]]]], dtype='float32')\n",
    "# Bias\n",
    "b_3 = np.array([-2.5], dtype='float32')\n",
    "\n",
    "# Forward Propagation: `o_2` und `o_3` berechnen\n",
    "o_2 = conv2d(o_1,w_2,b_2) # bitte Code ergaenzen <---------------- [Luecke (9)]\n",
    "o_3 = conv2d(o_2,w_3,b_3) # bitte Code ergaenzen <---------------- [Luecke (10)]\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print_tensors(tensors=(o_2, o_3), labels=('o_2', 'o_3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "<code style=\"padding: 0px\">\n",
    "o_2:\n",
    "[[[[ 6.  3.  7.]\n",
    "   [-7.  0.  3.]\n",
    "   [ 9.  3. -2.]]]]\n",
    "o_3:\n",
    "[[[[0.5]]]]\n",
    "</code>\n",
    "</details>\n",
    "\n",
    "---\n",
    "<a name=\"gradienten\"></a>\n",
    "**In der Vorlesung und in der Übung wurde gezeigt, dass sich die Berechnungen der Gradienten für die Filter-Gewichte und das Input Volume ebenfalls auf Faltungsoperationen zurückführen lassen. Für die Gradienten der Bias-Gewichte ist hingegen keine Faltungsoperationen notwendig.**\n",
    "\n",
    "Gradienten der Filter-Gewichte:\n",
    ">Die Gradienten der Filter-Gewichte ergeben sich aus der Faltung des Input\n",
    "Volumes mit den Gradienten des Output Volumes.\n",
    "\n",
    "Gradienten des Input Volumes:\n",
    "> Die Gradienten des Input Volumes ergeben sich aus der Faltung des mit\n",
    "Zero Padding um (Filtergröße - 1) erweiterten Gradienten des Output Volumes mit\n",
    "den um 180° gedrehten Filter-Gewichten.\n",
    "\n",
    "Die Gradienten der Filtergewichte können folglich ohne Probleme mit der bereits implementierten Convolution berechnet werden. Für die Bestimmung der Gradienten des Input Volumes muss die Convolution so erweitert werden, dass der Parameter `padding` ebenfalls ausgewertet wird.\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Folgende Funktionen könnten für die Vervollständigung der Lücken hilfreich sein:\n",
    "<ul style=\"margin-bottom: 0px; margin-top: 0px\">\n",
    "    <li><code style=\"background-color: #FAEAEA; padding: 0px\">np.pad</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.pad.html\" target=\"_blank\">NumPy-Dokumentation</a>\n",
    "        </li>\n",
    "    <li><code style=\"background-color: #FAEAEA; padding: 0px\">np.newaxis</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://numpy.org/doc/stable/user/basics.indexing.html#dimensional-indexing-tools\" target=\"_blank\">NumPy-Dokumentation</a>\n",
    "        </li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_with_padding(input_tensor, filter_tensor, bias_tensor, stride=(1, 1), padding=(0, 0), dilation=(1, 1), groups=1):\n",
    "    # Input Tensor mit Zero Padding zu `input_tensor_pad` erweitern\n",
    "    input_tensor_pad = np.pad(input_tensor, \n",
    "                              pad_width=((0,0),(0,0),(padding[0],padding[0]),(padding[1],padding[1])),\n",
    "                              mode = 'constant',\n",
    "                              constant_values=0)# bitte Code ergaenzen <---------------- [Luecke (11)]\n",
    "\n",
    "    # auf bereits implementierte Standard Convolution zurueckfuehren\n",
    "    return conv2d(input_tensor_pad, filter_tensor, bias_tensor,\n",
    "                  stride=stride,\n",
    "                  padding=(0, 0),\n",
    "                  dilation=dilation,\n",
    "                  groups=groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend kann eine Klasse `StandardConvolution` zur Berechnung der Forward Propagation und Backpropagation implementiert werden. Die Realisierung in Form einer Klasse ermöglicht das Speichern der Gewichte sowie des Input-Tensors für die Backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardConvolution:\n",
    "    def __init__(self, filter_tensor, bias_tensor):\n",
    "        # Gewichte speichern\n",
    "        self.weight = filter_tensor\n",
    "        self.bias = bias_tensor\n",
    "\n",
    "        # zum Speichern des Input Tensors\n",
    "        self.input_tensor = None\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # Input Tensor für spaetere Backpropagation speichern\n",
    "        self.input_tensor = input_tensor\n",
    "\n",
    "        return conv2d(input_tensor, self.weight,\n",
    "                      bias_tensor=self.bias,\n",
    "                      stride=(1,1), \n",
    "                      padding=(0,0),\n",
    "                      dilation=(1,1),\n",
    "                      groups=1) # bitte Code ergaenzen <---------------- [Luecke (12)]\n",
    "\n",
    "    def backward_bias(self, output_tensor_grad):\n",
    "        # Gradienten ergeben sich durch Multiplikation mit 1 und anschließender Summation ueber\n",
    "        # Batch-Achse sowie beiden raumlichen Achsen\n",
    "        return (output_tensor_grad * 1).sum(axis=(0, 2, 3))\n",
    "\n",
    "    def backward_weight(self, output_tensor_grad):\n",
    "        # Gradienten ergeben sich aus der Faltung des Input Volumes mit den Gradienten des Output Volumes\n",
    "\n",
    "        # leeren Tensor fuer Gradienten allokieren\n",
    "        weight_grad = np.zeros_like(self.weight)\n",
    "\n",
    "        # n_examples\n",
    "        n_examples = self.input_tensor.shape[0]\n",
    "\n",
    "        # die Gradienten ueber alle Beispiele im Batch aufaddieren\n",
    "        for ex in range(0, n_examples):\n",
    "            # fuer jedes Beispiel im Batch\n",
    "\n",
    "            # Input Volume und Gradient des Output Volume extrahieren\n",
    "            input_volume = self.input_tensor[ex]\n",
    "            output_volume_grad = output_tensor_grad[ex]\n",
    "\n",
    "            # Gradienten berechnen\n",
    "            # Beachten Sie, dass der Gradient der Output Feature Map fuer alle Input Feature Maps\n",
    "            # gleichermassen gilt. Durch eine Verschiebung der Channel-Achse auf die\n",
    "            # Batch-Achse und einer kuenstlichen neuen Channel-Achse (np.newaxis), kann die\n",
    "            # Berechnung fuer alle Input Feature Maps mit einer einzelnen Convolution\n",
    "            # durchgefuehrt werden. Im Anschluss werden die beiden Achsen zurueck getauscht.\n",
    "            conv2d_result = conv2d(input_volume[:, np.newaxis, :, :],\n",
    "                                   output_volume_grad[:, np.newaxis, :, :],\n",
    "                                   bias_tensor=None,\n",
    "                                   stride=(1, 1),\n",
    "                                   padding=(0, 0),\n",
    "                                   dilation=(1, 1),\n",
    "                                   groups=1)\n",
    "            weight_grad += conv2d_result.swapaxes(0, 1)\n",
    "        return weight_grad\n",
    "\n",
    "    def backward_input(self, output_tensor_grad):\n",
    "        # Gradienten ergeben sich aus der Faltung des mit Zero Padding um (Filtergröße - 1)\n",
    "        # erweiterten Gradienten des Output Volumes mit den um 180 Grad gedrehten Filter-Gewichten\n",
    "\n",
    "        # Groessen aus Groesse des Filter Tensors extrahieren\n",
    "        n_channels_out, n_channels_in, h_kernel, w_kernel = self.weight.shape\n",
    "\n",
    "        # Groessen aus Groesse des Gradienten Tensors extrahieren\n",
    "        n_examples, _, h_output_grad, w_output_grad = output_tensor_grad.shape\n",
    "\n",
    "        # Padding berechnen\n",
    "        h_pad = h_kernel - 1\n",
    "        w_pad = w_kernel - 1\n",
    "\n",
    "        # Groesse fuer Gradienten berechnen\n",
    "        h_input_grad, w_input_grad = \\\n",
    "            get_output_shape(input_shape=(h_output_grad, w_output_grad),\n",
    "                                          kernel_size=(h_kernel, w_kernel),\n",
    "                                          stride=(1, 1),\n",
    "                                          padding=(h_pad, w_pad),\n",
    "                                          dilation=(1, 1))\n",
    "\n",
    "        # leeren Tensor fuer Gradienten allokieren\n",
    "        input_grad = np.zeros((n_examples, n_channels_in, h_input_grad, w_input_grad),\n",
    "                              dtype='float32')\n",
    "\n",
    "        # Filter-Gewichte in den (height, width)-Dimensionen um 180 Grad drehen, bzw.\n",
    "        # zweimal spiegeln (an height (2) und width (3) Achse):\n",
    "        weight_rot180 = np.flip(np.flip(self.weight, axis=2), axis=3)\n",
    "\n",
    "        # die Gradienten fuer jede Input Feature Map uber alle Output Feature Maps aufaddieren\n",
    "        for ch_out in range(0, n_channels_out):\n",
    "            # fuer jede Output Feature Map in allen Beispielen im Batch\n",
    "\n",
    "            # Feature Maps und zugehoerige Gewichte extrahieren\n",
    "            feature_maps_grad = output_tensor_grad[:, ch_out, :, :]\n",
    "            weight_ch_out = weight_rot180[ch_out, :, :, :]\n",
    "\n",
    "            # Gradienten berechnen\n",
    "            # Beachten Sie, dass die Gradienten einer Output Feature Map fuer alle Beispiele\n",
    "            # im Batch gleichzeitig berechnet werden. Hierzu werden kuenstliche neue\n",
    "            # Channel-Achsen (np.newaxis) in den Tensoren ergaenzt.\n",
    "            input_grad += conv2d_with_padding(feature_maps_grad[:, np.newaxis, :, :],\n",
    "                                              weight_ch_out[:, np.newaxis, :, :],\n",
    "                                              bias_tensor=None,\n",
    "                                              stride=(1, 1),\n",
    "                                              padding=(h_pad, w_pad),\n",
    "                                              dilation=(1, 1),\n",
    "                                              groups=1)\n",
    "\n",
    "        return input_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Überprüfung:*\n",
    "\n",
    "Zur Überprüfung können nun die kompletten Ergebnisse für die letzten beiden Convolutions aus Teilaufgabe (a) reproduziert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o_2:\n",
      "[[[[ 6.  3.  7.]\n",
      "   [-7.  0.  3.]\n",
      "   [ 9.  3. -2.]]]]\n",
      "o_3:\n",
      "[[[[0.5]]]]\n",
      "E:\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "# Schichten anlegen\n",
    "conv2 = StandardConvolution(w_2, b_2)\n",
    "conv3 = StandardConvolution(w_3, b_3)\n",
    "\n",
    "# Forward Propagation: `o_2` und `o_3` berechnen\n",
    "o_2 = conv2.forward(o_1) # bitte Code ergaenzen <---------------- [Luecke (13)]\n",
    "o_3 = conv3.forward(o_2) # bitte Code ergaenzen <---------------- [Luecke (14)]\n",
    "y = o_3.squeeze()    # zusaetzliche Achsen entfernen\n",
    "\n",
    "# Fehler bestimmen\n",
    "t = 0\n",
    "e_mse = (y-t)**2\n",
    "print_tensors(tensors=(o_2, o_3, e_mse), labels=('o_2', 'o_3', 'E'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "<code style=\"padding: 0px\">\n",
    "o_2:\n",
    "[[[[ 6.  3.  7.]\n",
    "   [-7.  0.  3.]\n",
    "   [ 9.  3. -2.]]]]\n",
    "o_3:\n",
    "[[[[0.5]]]]\n",
    "E:\n",
    "0.25\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dEdb_3:\n",
      "[1.]\n",
      "dEdw_3:\n",
      "[[[[ 6.  3.  7.]\n",
      "   [-7.  0.  3.]\n",
      "   [ 9.  3. -2.]]]]\n",
      "dEdo_2:\n",
      "[[[[ 1.  1.  2.]\n",
      "   [ 3.  0.  1.]\n",
      "   [-1.  1. -2.]]]]\n",
      "b_3_new:\n",
      "[-2.5005]\n",
      "w_3_new:\n",
      "[[[[ 0.997   0.9985  1.9965]\n",
      "   [ 3.0035  0.      0.9985]\n",
      "   [-1.0045  0.9985 -1.999 ]]]]\n",
      "dEdb_2:\n",
      "[6.]\n",
      "dEdw_2:\n",
      "[[[[13.  6.]\n",
      "   [ 3.  7.]]]]\n",
      "dEdo_1:\n",
      "[[[[-2. -3. -5. -2.]\n",
      "   [-5.  0.  2.  3.]\n",
      "   [ 5.  5.  4.  4.]\n",
      "   [-1. -1.  0. -4.]]]]\n",
      "b_2_new:\n",
      "[2.997]\n",
      "w_2_new:\n",
      "[[[[-2.0065 -1.003 ]\n",
      "   [ 0.9985  1.9965]]]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 14px;font-weight: bold;width: auto;margin: 0px 0px 0px 0em;padding: 0px;\">Überprüfung der Ergebnisse für 'backpropagation':</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient 'dedb_3':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"width: auto;margin: 0px 0px 0px 5em;paddding: 0px;color: #008000;font-weight: bold;\">&#10003;</span>&nbsp;&nbsp;<span style=\"display: none;\" id=\"hidden_result\">{\"test\": \"dedb_3_0\", \"time\": \"2022/11/21, 18:46:02\", \"passed\": true}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient 'dedw_3':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"width: auto;margin: 0px 0px 0px 5em;paddding: 0px;color: #008000;font-weight: bold;\">&#10003;</span>&nbsp;&nbsp;<span style=\"display: none;\" id=\"hidden_result\">{\"test\": \"dedw_3_0\", \"time\": \"2022/11/21, 18:46:02\", \"passed\": true}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient 'dedo_2':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"width: auto;margin: 0px 0px 0px 5em;paddding: 0px;color: #008000;font-weight: bold;\">&#10003;</span>&nbsp;&nbsp;<span style=\"display: none;\" id=\"hidden_result\">{\"test\": \"dedo_2_0\", \"time\": \"2022/11/21, 18:46:02\", \"passed\": true}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neue Bias-Gewichte 'b_3_new':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"width: auto;margin: 0px 0px 0px 5em;paddding: 0px;color: #008000;font-weight: bold;\">&#10003;</span>&nbsp;&nbsp;<span style=\"display: none;\" id=\"hidden_result\">{\"test\": \"b_3_new_0\", \"time\": \"2022/11/21, 18:46:02\", \"passed\": true}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neue Filter-Gewichte 'w_3_new':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"width: auto;margin: 0px 0px 0px 5em;paddding: 0px;color: #008000;font-weight: bold;\">&#10003;</span>&nbsp;&nbsp;<span style=\"display: none;\" id=\"hidden_result\">{\"test\": \"w_3_new_0\", \"time\": \"2022/11/21, 18:46:02\", \"passed\": true}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient 'dedb_2':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"width: auto;margin: 0px 0px 0px 5em;paddding: 0px;color: #008000;font-weight: bold;\">&#10003;</span>&nbsp;&nbsp;<span style=\"display: none;\" id=\"hidden_result\">{\"test\": \"dedb_2_0\", \"time\": \"2022/11/21, 18:46:02\", \"passed\": true}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient 'dedw_2':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"width: auto;margin: 0px 0px 0px 5em;paddding: 0px;color: #008000;font-weight: bold;\">&#10003;</span>&nbsp;&nbsp;<span style=\"display: none;\" id=\"hidden_result\">{\"test\": \"dedw_2_0\", \"time\": \"2022/11/21, 18:46:02\", \"passed\": true}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient 'dedo_1':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"width: auto;margin: 0px 0px 0px 5em;paddding: 0px;color: #008000;font-weight: bold;\">&#10003;</span>&nbsp;&nbsp;<span style=\"display: none;\" id=\"hidden_result\">{\"test\": \"dedo_1_0\", \"time\": \"2022/11/21, 18:46:02\", \"passed\": true}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neue Bias-Gewichte 'b_2_new':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"width: auto;margin: 0px 0px 0px 5em;paddding: 0px;color: #008000;font-weight: bold;\">&#10003;</span>&nbsp;&nbsp;<span style=\"display: none;\" id=\"hidden_result\">{\"test\": \"b_2_new_0\", \"time\": \"2022/11/21, 18:46:02\", \"passed\": true}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neue Filter-Gewichte 'w_2_new':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"width: auto;margin: 0px 0px 0px 5em;paddding: 0px;color: #008000;font-weight: bold;\">&#10003;</span>&nbsp;&nbsp;<span style=\"display: none;\" id=\"hidden_result\">{\"test\": \"w_2_new_0\", \"time\": \"2022/11/21, 18:46:02\", \"passed\": true}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eta = 0.0005\n",
    "\n",
    "# Backpropagation Fehler\n",
    "dedy = 2*(y-t)\n",
    "dedo_3 = dedy.reshape(o_3.shape)    # zusaetzliche Achsen wiederherstellen\n",
    "\n",
    "# Backpropagation Convolution 3: `dedb_3`, `dedw_3` und `dedo_2` bestimmen\n",
    "dedb_3 = conv3.backward_bias(dedo_3) # bitte Code ergaenzen <---------------- [Luecke (15)]\n",
    "dedw_3 = conv3.backward_weight(dedo_3) # bitte Code ergaenzen <---------------- [Luecke (16)]\n",
    "dedo_2 = conv3.backward_input(dedo_3) # bitte Code ergaenzen <---------------- [Luecke (17)]\n",
    "\n",
    "b_3_new = b_3 - eta*dedb_3\n",
    "w_3_new = w_3 - eta*dedw_3\n",
    "\n",
    "print_tensors(tensors=(dedb_3, dedw_3, dedo_2, b_3_new, w_3_new),\n",
    "              labels=('dEdb_3', 'dEdw_3', 'dEdo_2', 'b_3_new', 'w_3_new'),\n",
    "              precision=4)\n",
    "\n",
    "# Backpropagation Convolution 2: `dedb_2`, `dedw_2` und `dedo_1` bestimmen\n",
    "dedb_2 = conv2.backward_bias(dedo_2) # bitte Code ergaenzen <---------------- [Luecke (18)]\n",
    "dedw_2 = conv2.backward_weight(dedo_2) # bitte Code ergaenzen <---------------- [Luecke (19)]\n",
    "dedo_1 = conv2.backward_input(dedo_2) # bitte Code ergaenzen <---------------- [Luecke (20)]\n",
    "\n",
    "b_2_new = b_2 - eta*dedb_2\n",
    "w_2_new = w_2 - eta*dedw_2\n",
    "\n",
    "print_tensors(tensors=(dedb_2, dedw_2, dedo_1, b_2_new, w_2_new),\n",
    "              labels=('dEdb_2', 'dEdw_2', 'dEdo_1', 'b_2_new', 'w_2_new'),\n",
    "              precision=4)\n",
    "\n",
    "interactive_check('backpropagation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "<code style=\"padding: 0px\">\n",
    "dEdb_3:\n",
    "[1.]\n",
    "dEdw_3:\n",
    "[[[[ 6.  3.  7.]\n",
    "   [-7.  0.  3.]\n",
    "   [ 9.  3. -2.]]]]\n",
    "dEdo_2:\n",
    "[[[[ 1.  1.  2.]\n",
    "   [ 3.  0.  1.]\n",
    "   [-1.  1. -2.]]]]\n",
    "b_3_new:\n",
    "[-2.5005]\n",
    "w_3_new:\n",
    "[[[[ 0.997   0.9985  1.9965]\n",
    "   [ 3.0035  0.      0.9985]\n",
    "   [-1.0045  0.9985 -1.999 ]]]]\n",
    "dEdb_2:\n",
    "[6.]\n",
    "dEdw_2:\n",
    "[[[[13.  6.]\n",
    "   [ 3.  7.]]]]\n",
    "dEdo_1:\n",
    "[[[[-2. -3. -5. -2.]\n",
    "   [-5.  0.  2.  3.]\n",
    "   [ 5.  5.  4.  4.]\n",
    "   [-1. -1.  0. -4.]]]]\n",
    "b_2_new:\n",
    "[2.997]\n",
    "w_2_new:\n",
    "[[[[-2.0065 -1.003 ]\n",
    "   [ 0.9985  1.9965]]]]\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 5px\">\n",
    "\n",
    "<a name=\"praktikum\"></a>\n",
    "<h3 style=\"color: #aa0000;\">Praktikumsaufgabe P6.1: Strided Convolution</h3>\n",
    "\n",
    "Beziehen Sie zusätzlich noch die Convolution der ersten Schicht (Strided Convolution) mit in die Betrachtungen ein und reproduzieren Sie die Ergebnisse aus Teilaufgabe (a) ebenfalls für diese Convolution.\n",
    "\n",
    "---\n",
    "**Erweitern Sie hierzu zunächst die Funktion `conv2d` so, dass ebenfalls Strided Convolutions realisiert werden können.**\n",
    "\n",
    "*Implementierung:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_tensor, filter_tensor, bias_tensor=None, stride=(1, 1), padding=(0, 0), dilation=(1, 1), groups=1):\n",
    "    # ueberpruefen, ob gueltige Parameter uebergeben wurden, andernfalls nicht implementiert als Fehler zurueckgeben\n",
    "    assert padding == (0, 0), \"Not implemented\"\n",
    "    assert dilation == (1, 1), \"Not implemented\"\n",
    "    assert groups == 1, \"Not implemented\"\n",
    "\n",
    "    # Groessen aus Groesse des Input Tensors extrahieren\n",
    "    n_examples, n_channels_in, h_in, w_in = input_tensor.shape\n",
    "\n",
    "    # Groessen aus Groesse des Filter Tensors extrahieren\n",
    "    n_channels_out, n_channels_in_kernel, h_kernel, w_kernel = filter_tensor.shape\n",
    "\n",
    "    # kleiner Check: sofern keine Grouped Convolution oder Depthwise Convolution sind beide identisch\n",
    "    assert n_channels_in == n_channels_in_kernel, \"Not implemented\"\n",
    "\n",
    "    # Groesse `(h_out, w_out)` der Output Feature Maps bestimmen\n",
    "    h_out, w_out = get_output_shape(input_shape=(h_in, w_in),\n",
    "                                    kernel_size=(h_kernel, w_kernel),\n",
    "                                    stride=stride,\n",
    "                                    padding=padding,\n",
    "                                    dilation=dilation)\n",
    "\n",
    "    # leeren Output Tensor allokieren\n",
    "    output_tensor = np.zeros((n_examples, n_channels_out, h_out, w_out), dtype=np.float32)\n",
    "\n",
    "    # Output berechnen\n",
    "    for ex in range(0, n_examples):\n",
    "        # fuer jedes Beispiel im Batch\n",
    "\n",
    "        for ch_out in range(0, n_channels_out):\n",
    "            # fuer jeden Output Channel\n",
    "\n",
    "            for i in range(0, h_out):\n",
    "                # fuer jede y-Position i der Hoehe der Output Feature Maps\n",
    "\n",
    "                for j in range(0, w_out):\n",
    "                    # fuer jede x-Position j der Breite der Output Feature Maps\n",
    "\n",
    "                    # Slices `vertical` und `horizontal` fuer relevanten Teil in den Input Feature Maps\n",
    "                    # ausgehend von aktueller Position i und j bestimmen\n",
    "                    vertical = slice(i,i+h_kernel) # bitte Code ergaenzen <---------------- [Luecke (21)]\n",
    "                    horizontal = slice(j,j+w_kernel) # bitte Code ergaenzen <---------------- [Luecke (22)]\n",
    "\n",
    "                    # Ergebnisse fuer jeden Input Channel akkumulieren\n",
    "                    for ch_in in range(0, n_channels_in):\n",
    "                        # für jeden Input Channel\n",
    "\n",
    "                        # Teil der Input Feature Map `input_window` aus Input Tensor extrahieren\n",
    "                        input_window = input_tensor[ex, ch_in, vertical, horizontal]\n",
    "\n",
    "                        # 2D Filter `weight` aus Filter Tensor extrahieren\n",
    "                        weight = filter_tensor[ch_out, ch_in, :, :]\n",
    "\n",
    "                        # elementweise Multiplikation des Fenster mit Filtergewichten\n",
    "                        # und anschliessende Summation\n",
    "                        result = np.sum(input_window * weight, axis=None)\n",
    "\n",
    "                        # Ergebnis zum bisherigen Ergebnis hinzuaddieren\n",
    "                        output_tensor[ex, ch_out, i, j] += result\n",
    "\n",
    "                    # nach der Faltung zur Feature Map gehoerendes Bias Gewicht addieren\n",
    "                    if bias_tensor is not None:\n",
    "                        output_tensor[ex, ch_out, i, j] += bias_tensor[ch_out]\n",
    "\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Überprüfung:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o_1:\n",
      "[[[[ 1. -1.  2. -2.]\n",
      "   [ 3. -3.  1. -1.]\n",
      "   [ 3. -2.  2. -2.]\n",
      "   [ 1.  1.  0.  0.]]]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 14px;font-weight: bold;width: auto;margin: 0px 0px 0px 0em;padding: 0px;\">Überprüfung der Ergebnisse für 'conv1_forward':</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Tensor 'o_1':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"width: auto;margin: 0px 0px 0px 5em;paddding: 0px;color: #f00;font-weight: bold;\">&#10007;</span>&nbsp;&nbsp;<span style=\"display: none;\" id=\"hidden_result\">{\"test\": \"o_1_0\", \"time\": \"2022/11/21, 19:04:27\", \"passed\": false}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 14px;color: #f00;width: auto;margin: 0px 0px 0px 5em;padding: 0px;\">Ausgabe nicht korrekt</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Forward Propagation: `o_1` berechnen\n",
    "o_1 = conv2d(o_0,w_1,b_1,stride=(2,2)) # bitte Code ergaenzen <---------------- [Luecke (23)]\n",
    "\n",
    "# Ergebnis ausgeben\n",
    "print_tensors(tensors=o_1, labels='o_1')\n",
    "\n",
    "# Ergebnis ueberpruefen\n",
    "interactive_check('conv1_forward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "<code style=\"padding: 0px\">\n",
    "o_1:\n",
    "[[[[ 1.  2.  0. -1.]\n",
    "   [ 3.  2.  1.  1.]\n",
    "   [-2.  0.  1.  1.]\n",
    "   [ 0.  1.  0. -1.]]]]\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Implementieren Sie anschließend eine Klasse `StridedConvolution`, mit der alle fehlenden Ergebnisse und die Gradienten in Richtung der Netzwerkeingabe `o_0` bestimmt werden können.**\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Neben den Betrachtungen in der Übungsaufgabe, könnte folgende Literaturstelle für die Vervollständigung der Lücken hilfreich sein:\n",
    "<ul style=\"margin-bottom: 0px; margin-top: 0px\">\n",
    "    <li>Dumoulin, et. al.: <i>A guide to convolution arithmetic for deep learning</i>, arXiv 2016.&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://arxiv.org/pdf/1603.07285.pdf\" target=\"_blank\">arXiv</a>\n",
    "        </li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "*Implementierung:*\n",
    "\n",
    "Die Realisierung wird erfordern, dass an verschiedenen Stellen eine Dilation eingebracht werden muss.\n",
    "Hierzu können Sie die nachfolgende Hilfsfunktion verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dilation(tensor, dilation=(1, 1)):\n",
    "    d0, d1, h, w = tensor.shape\n",
    "    h_r, w_r = dilation\n",
    "\n",
    "    tensor_dilated = np.zeros((d0, d1, (h-1)*h_r + 1, (w-1)*w_r +1),\n",
    "                              dtype='float32')\n",
    "    tensor_dilated[:, :, ::h_r, ::w_r] = tensor\n",
    "    return tensor_dilated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Veranschaulichung der Funktionsweise soll folgendes Beispiel dienen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\n",
      "[[[[1 2 3]\n",
      "   [4 5 6]\n",
      "   [7 8 9]]]]\n",
      "Tensor mit Dilation r=2:\n",
      "[[[[1. 0. 2. 0. 3.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [4. 0. 5. 0. 6.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [7. 0. 8. 0. 9.]]]]\n"
     ]
    }
   ],
   "source": [
    "tensor = np.arange(1, 10).reshape((1, 1, 3, 3))\n",
    "tensor_r2 = add_dilation(tensor, dilation=(2, 2))\n",
    "\n",
    "print_tensors(tensors=(tensor, tensor_r2),\n",
    "              labels=('Tensor', 'Tensor mit Dilation r=2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realisierung der Klasse `StridedConvolution`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StridedConvolution(StandardConvolution):\n",
    "    def __init__(self, filter_tensor, bias_tensor, stride):\n",
    "        super(StridedConvolution, self).__init__(filter_tensor, bias_tensor)\n",
    "\n",
    "        # Stride speichern\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # Input Tensor für spaetere Backpropagation speichern\n",
    "        self.input_tensor = input_tensor\n",
    "\n",
    "        # Anpassungen fuer StridedConvolution\n",
    "        return # bitte Code ergaenzen <---------------- [Luecke (24)]\n",
    "\n",
    "    def backward_weight(self, output_tensor_grad):\n",
    "        # Anpassungen fuer StridedConvolution\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (25)]\n",
    "\n",
    "        # Implementierung in Basisklasse wiederverwenden\n",
    "        return super(StridedConvolution, self).backward_weight(output_tensor_grad)\n",
    "\n",
    "    def backward_input(self, output_tensor_grad):\n",
    "        # Anpassungen fuer StridedConvolution\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (26)]\n",
    "\n",
    "        # Implementierung in Basisklasse wiederverwenden\n",
    "        return super(StridedConvolution, self).backward_input(output_tensor_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Überprüfung:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dedb_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m o_1 \u001b[38;5;241m=\u001b[39m conv1\u001b[38;5;241m.\u001b[39mforward(o_0)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Backpropagation Convolution 1: `dedb_1`, `dedw_1` und `dedo_0` bestimmen\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# bitte Code ergaenzen <---------------- [Luecke (27)]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# bitte Code ergaenzen <---------------- [Luecke (28)]\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# bitte Code ergaenzen <---------------- [Luecke (29)]\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m b_1_new \u001b[38;5;241m=\u001b[39m b_1 \u001b[38;5;241m-\u001b[39m eta\u001b[38;5;241m*\u001b[39m\u001b[43mdedb_1\u001b[49m\n\u001b[1;32m     13\u001b[0m w_1_new \u001b[38;5;241m=\u001b[39m w_1 \u001b[38;5;241m-\u001b[39m eta\u001b[38;5;241m*\u001b[39mdedw_1\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Ergebnisse ausgeben\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dedb_1' is not defined"
     ]
    }
   ],
   "source": [
    "# Schicht anlegen\n",
    "conv1 = StridedConvolution(w_1, b_1, stride=(2, 2))\n",
    "\n",
    "# Forward Propagation Convolution 1\n",
    "o_1 = conv1.forward(o_0)\n",
    "\n",
    "# Backpropagation Convolution 1: `dedb_1`, `dedw_1` und `dedo_0` bestimmen\n",
    "# bitte Code ergaenzen <---------------- [Luecke (27)]\n",
    "# bitte Code ergaenzen <---------------- [Luecke (28)]\n",
    "# bitte Code ergaenzen <---------------- [Luecke (29)]\n",
    "\n",
    "b_1_new = b_1 - eta*dedb_1\n",
    "w_1_new = w_1 - eta*dedw_1\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print_tensors(tensors=(dedb_1, dedw_1, dedo_0, b_1_new, w_1_new),\n",
    "              labels=('dEdb_1', 'dEdw_1', 'dEdo_0', 'b_1_new', 'w_1_new'),\n",
    "              precision=4)\n",
    "\n",
    "# Ergebnisse ueberpruefen\n",
    "interactive_check('conv1_backward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "<code style=\"padding: 0px\">\n",
    "dEdb_1:\n",
    "[0.]\n",
    "dEdw_1:\n",
    "[[[[-14.  -3.]\n",
    "   [ -1.  -8.]]]]\n",
    "dEdo_0:\n",
    "[[[[ -4.   4.  -6.   6. -10.  10.  -4.   4.]\n",
    "   [ -2.   2.  -3.   3.  -5.   5.  -2.   2.]\n",
    "   [-10.  10.   0.   0.   4.  -4.   6.  -6.]\n",
    "   [ -5.   5.   0.   0.   2.  -2.   3.  -3.]\n",
    "   [ 10. -10.  10. -10.   8.  -8.   8.  -8.]\n",
    "   [  5.  -5.   5.  -5.   4.  -4.   4.  -4.]\n",
    "   [ -2.   2.  -2.   2.   0.   0.  -8.   8.]\n",
    "   [ -1.   1.  -1.   1.   0.   0.  -4.   4.]]]]\n",
    "b_1_new:\n",
    "[0.]\n",
    "w_1_new:\n",
    "[[[[ 2.007  -1.9985]\n",
    "   [ 1.0005 -0.996 ]]]]\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 5px\">\n",
    "\n",
    "### (g) Vergleichen Sie die Ergebnisse Ihrer NumPy-Implementierung mit einer PyTorch-Implementierung.\n",
    "\n",
    "---\n",
    "Pakete importieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Netzwerk implementieren:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, print_tensors=True):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Schicht 1 `self.conv1` anlegen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (30)]\n",
    "\n",
    "        # Schicht 2 `self.conv2` anlegen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (31)]\n",
    "\n",
    "        # Schicht 3 `self.conv3` anlegen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (32)]\n",
    "\n",
    "        # Gewichte mit bereits definierten Variablen initialisieren\n",
    "        self.conv1.weight.data = torch.tensor(w_1)\n",
    "        self.conv1.bias.data = torch.tensor(b_1)\n",
    "        self.conv2.weight.data = torch.tensor(w_2)\n",
    "        self.conv2.bias.data = torch.tensor(b_2)\n",
    "        self.conv3.weight.data = torch.tensor(w_3)\n",
    "        self.conv3.bias.data = torch.tensor(b_3)\n",
    "\n",
    "        self.print_tensors = print_tensors\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolution 1: `o_1` bestimmen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (33)]\n",
    "\n",
    "        # Convolution 2: `o_2` bestimmen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (34)]\n",
    "\n",
    "        # Convolution 3: `o_3` bestimmen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (35)]\n",
    "\n",
    "        y = o_3.view(-1, 1)\n",
    "\n",
    "        if self.print_tensors:\n",
    "            x.register_hook(lambda grad: print_tensors(grad, 'o_0.grad'))\n",
    "            o_1.register_hook(lambda grad: print_tensors(grad, 'o_1.grad'))\n",
    "            o_2.register_hook(lambda grad: print_tensors(grad, 'o_2.grad'))\n",
    "            o_3.register_hook(lambda grad: print_tensors(grad, 'o_3.grad'))\n",
    "            print_tensors(tensors=(o_1, o_2, o_3),\n",
    "                          labels=('o_1', 'o_2', 'o_3'))\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Netzwerkobjekt anlegen, auf Eingabe anwenden und Fehler berechnen:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netzwerkobjekt anlegen\n",
    "network = CNN()\n",
    "\n",
    "# Eingabe konvertieren\n",
    "o_0_pytorch = torch.tensor(o_0, requires_grad=True)\n",
    "\n",
    "# Netzwerkobjekt auf Eingabe anwenden\n",
    "y = network(o_0_pytorch)\n",
    "\n",
    "# Fehler berechnen und ausgeben\n",
    "t = torch.tensor([[0]], dtype=torch.float32)\n",
    "e = F.mse_loss(y, t)\n",
    "\n",
    "print_tensors(tensors=e, labels='E')\n",
    "\n",
    "# Backpropagation\n",
    "e.backward()\n",
    "\n",
    "# Gradienten ausgeben\n",
    "for n, p in network.named_parameters():\n",
    "    print_tensors(tensors=p.grad, labels=f\"{n}.grad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "<code style=\"padding: 0px\">\n",
    "o_1:\n",
    "[[[[ 1.  2.  0. -1.]\n",
    "   [ 3.  2.  1.  1.]\n",
    "   [-2.  0.  1.  1.]\n",
    "   [ 0.  1.  0. -1.]]]]\n",
    "o_2:\n",
    "[[[[ 6.  3.  7.]\n",
    "   [-7.  0.  3.]\n",
    "   [ 9.  3. -2.]]]]\n",
    "o_3:\n",
    "[[[[0.5]]]]\n",
    "E:\n",
    "0.25\n",
    "o_3.grad:\n",
    "[[[[1.]]]]\n",
    "o_2.grad:\n",
    "[[[[ 1.  1.  2.]\n",
    "   [ 3.  0.  1.]\n",
    "   [-1.  1. -2.]]]]\n",
    "o_1.grad:\n",
    "[[[[-2. -3. -5. -2.]\n",
    "   [-5.  0.  2.  3.]\n",
    "   [ 5.  5.  4.  4.]\n",
    "   [-1. -1.  0. -4.]]]]\n",
    "o_0.grad:\n",
    "[[[[ -4.   4.  -6.   6. -10.  10.  -4.   4.]\n",
    "   [ -2.   2.  -3.   3.  -5.   5.  -2.   2.]\n",
    "   [-10.  10.   0.   0.   4.  -4.   6.  -6.]\n",
    "   [ -5.   5.   0.   0.   2.  -2.   3.  -3.]\n",
    "   [ 10. -10.  10. -10.   8.  -8.   8.  -8.]\n",
    "   [  5.  -5.   5.  -5.   4.  -4.   4.  -4.]\n",
    "   [ -2.   2.  -2.   2.   0.   0.  -8.   8.]\n",
    "   [ -1.   1.  -1.   1.   0.   0.  -4.   4.]]]]\n",
    "conv1.weight.grad:\n",
    "[[[[-14.  -3.]\n",
    "   [ -1.  -8.]]]]\n",
    "conv1.bias.grad:\n",
    "[0.]\n",
    "conv2.weight.grad:\n",
    "[[[[13.  6.]\n",
    "   [ 3.  7.]]]]\n",
    "conv2.bias.grad:\n",
    "[6.]\n",
    "conv3.weight.grad:\n",
    "[[[[ 6.  3.  7.]\n",
    "   [-7.  0.  3.]\n",
    "   [ 9.  3. -2.]]]]\n",
    "conv3.bias.grad:\n",
    "[1.]\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 5px\">\n",
    "\n",
    "### (h) Führen Sie in Ihrer Implementierung eine weitere Forward Propagation mit den aktualisierten Gewichten durch. Wird mit den neuen Gewichten ein geringerer Fehler erzielt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netzwerkobjekt anlegen\n",
    "network = CNN(print_tensors=False)\n",
    "\n",
    "# Optimierer anlegen\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr=0.0005, momentum=0.0, nesterov=False)\n",
    "\n",
    "# Eingabe konvertieren\n",
    "o_0_pytorch = torch.tensor(o_0, requires_grad=False)\n",
    "\n",
    "for epoch in range(2):\n",
    "    # Netzwerkobjekt auf Eingabe anwenden\n",
    "    y = network(o_0_pytorch)\n",
    "\n",
    "    # Fehler berechnen und ausgeben\n",
    "    t = torch.tensor([[0]], dtype=torch.float32)\n",
    "    e = F.mse_loss(y, t)\n",
    "    print_tensors(tensors=e, labels=f'E (t={epoch+1})', precision=4)\n",
    "\n",
    "    # Backpropagation: Gradienten bestimmen und Lernschritt ausfuehren\n",
    "    # bitte Code ergaenzen <---------------- [Luecke (36)]\n",
    "    # bitte Code ergaenzen <---------------- [Luecke (37)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "<code style=\"padding: 0px\">\n",
    "E (t=1):\n",
    "0.25\n",
    "E (t=2):\n",
    "0.0083\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 5px\">\n",
    "\n",
    "<a name=\"praktikum2\"></a>\n",
    "<h3 style=\"color: #aa0000;\">Praktikumsaufgabe P6.2: Convolution mit Dilation & Padding</h3>\n",
    "\n",
    "Leiten Sie anhand systematischer Experimente ab, welche Ableitungen sich ausgehend von den Fehlergradienten am Output $\\dfrac{\\partial E}{\\partial O^{(l)}}$ einer Schicht in Richtung der Filter-Gewichte $W^{(l)}$ und des Inputs $O^{(l-1)}$ bei Verwendung der nachfolgenden Convolutions ergeben.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Folgende Literaturstelle könnte für die Vervollständigung der Lücken hilfreich sein:\n",
    "<ul style=\"margin-bottom: 0px; margin-top: 0px\">\n",
    "    <li>Dumoulin, et. al.: <i>A guide to convolution arithmetic for deep learning</i>, arXiv 2016.&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://arxiv.org/pdf/1603.07285.pdf\" target=\"_blank\">arXiv</a>\n",
    "        </li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie, dass die für die Faltungen realisierten Klassen stets von der nachfolgenden Klasse (`ConvolutionBase`) ableiten sollten - diese Basisklasse untersützt bereits eine Funktion zur Realisierung einer Faltungsoperation (`self.conv2d`) mit allen bekannten Parametern. Es ist daher nicht notwendig, die oben im Notebook verwendeten Funktionen händisch zu erweitern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tui_dl4cv.cnn import ConvolutionBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgende Funktionen werden an verschiedenen Stellen benötigt und untersützen Sie bei der Realisierung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_180(tensor):\n",
    "    \"\"\"Tensor entlang der raeumlichen Dimensionen um 180 Grad drehen\"\"\"\n",
    "    return np.flip(np.flip(tensor, axis=2), axis=3)\n",
    "\n",
    "def swap_axes(tensor, axis1=0, axis2=1):\n",
    "    \"\"\"Zwei Achsen innerhalb eines Tensors tauschen\"\"\"\n",
    "    return np.swapaxes(tensor, axis1=axis1, axis2=axis2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nutzen Sie zudem die vorgesehene Überprüfung zur Validierung Ihrer Impelemtierung.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "<b>Hinweis</b>: Falls einige der Tests fehlschlegen, wird eine entsprechende Fehlermeldung ausgegeben. Beachten Sie, dass die Fehler in '[Optional]' und '[Obligatorisch]' unterteilt sind. Damit Sie die volle Punktzahl erhalten, dürfen keine mit '[Obligatorisch]' gekennzeichneten Fehler auftreten.</div>\n",
    "\n",
    "---\n",
    "**Dilated Convolution:**\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Kanalanzahl Input } n^{(l-1)} = 1\\\\[4mm]\n",
    "\\text{Kanalanzahl Output } n^{(l)} = 1, \\; \\text{Filtergröße } k^{(l)} = 2, \\; \\text{Stride } s^{(l)} = 1, \\; \\text{Padding } p^{(l)} = 0, \\; \\text{Dilation } r^{(l)} = 2, \\; \\text{Groups } g^{(l)} = 1\n",
    "\\end{equation}\n",
    "\n",
    "Beschreiben Sie <u>ganz kurz</u>, wie die Convolution parametriert und durchgeführt werden muss.\n",
    "Untermauern Sie Ihre Argumentationen durch das Einsetzen geeigneter Parameter in nachfolgenden Code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ff0000;\">(Anpassung der Antwort durch Doppelklick hier)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class DilatedConvolution(ConvolutionBase):\n",
    "    def __init__(self):\n",
    "        # oben definierte Parameter weitergeben, im Nachgang ebenfalls als self.* verfuegbar\n",
    "        super().__init__(\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            kernel_size=2,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            dilation=2,\n",
    "            groups=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def backward_input(self, output_tensor_grad):\n",
    "        weight_tensor = self.weight\n",
    "\n",
    "        # Parameter und Eingaben fuer Faltung definieren\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (38)]\n",
    "        stride =\n",
    "        padding =\n",
    "        dilation =\n",
    "        groups =\n",
    "\n",
    "        input_ =\n",
    "        filter_ =\n",
    "\n",
    "        # Faltungsoperation durchfuehren (sollte nicht veraendert werden)\n",
    "        return self.conv2d(input_, filter_,\n",
    "                           stride=stride,\n",
    "                           padding=padding,\n",
    "                           dilation=dilation,\n",
    "                           groups=groups)\n",
    "\n",
    "    def backward_weight(self, output_tensor_grad):\n",
    "        # Parameter und Eingaben fuer Faltung definieren\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (39)]\n",
    "        stride =\n",
    "        padding =\n",
    "        dilation =\n",
    "        groups =\n",
    "\n",
    "        input_ =\n",
    "        filter_ =\n",
    "\n",
    "        # Faltungsoperation durchfuehren (sollte nicht veraendert werden)\n",
    "        return swap_axes(self.conv2d(input_, filter_,\n",
    "                                     stride=stride,\n",
    "                                     padding=padding,\n",
    "                                     dilation=dilation,\n",
    "                                     groups=groups))\n",
    "\n",
    "# Objekt der Schicht erstellen\n",
    "conv = DilatedConvolution()\n",
    "\n",
    "# exemparische Anwendung (fuer Testzwecke und Verstaendnisexperimente)\n",
    "x = np.ones((1, 1, 4, 4))\n",
    "y = conv(x)\n",
    "dedy = np.ones_like(y)\n",
    "dedw = conv.backward_weight(dedy)\n",
    "dedx = conv.backward_input(dedy)\n",
    "print_tensors(tensors=(conv.weight, x, y, dedy, dedw, dedx),\n",
    "              labels=('weight', 'x', 'y', 'dedy', 'dedw', 'dedx'))\n",
    "\n",
    "# Impelementierung ueberpruefen\n",
    "interactive_check('dilated_conv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Convolution mit Padding:**\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Kanalanzahl Input } n^{(l-1)} = 1\\\\[4mm]\n",
    "\\text{Kanalanzahl Output } n^{(l)} = 1, \\; \\text{Filtergröße } k^{(l)} = 3, \\; \\text{Stride } s^{(l)} = 1, \\; \\text{Padding } p^{(l)} = 1, \\; \\text{Dilation } r^{(l)} = 1, \\; \\text{Groups } g^{(l)} = 1\n",
    "\\end{equation}\n",
    "\n",
    "Beschreiben Sie <u>ganz kurz</u>, wie die Convolution parametriert und durchgeführt werden muss.\n",
    "Untermauern Sie Ihre Argumentationen durch das Einsetzen geeigneter Parameter in nachfolgenden Code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ff0000;\">(Anpassung der Antwort durch Doppelklick hier)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionWithPadding(ConvolutionBase):\n",
    "    def __init__(self):\n",
    "        # oben definierte Parameter weitergeben, im Nachgang ebenfalls als self.* verfuegbar\n",
    "        super().__init__(\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            dilation=1,\n",
    "            groups=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def backward_input(self, output_tensor_grad):\n",
    "        weight_tensor = self.weight\n",
    "\n",
    "        # Parameter und Eingaben fuer Faltung definieren\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (40)]\n",
    "        stride =\n",
    "        padding =\n",
    "        dilation =\n",
    "        groups =\n",
    "\n",
    "        input_ =\n",
    "        filter_ =\n",
    "\n",
    "        # Faltungsoperation durchfuehren (sollte nicht veraendert werden)\n",
    "        return self.conv2d(input_, filter_,\n",
    "                           stride=stride,\n",
    "                           padding=padding,\n",
    "                           dilation=dilation,\n",
    "                           groups=groups)\n",
    "\n",
    "    def backward_weight(self, output_tensor_grad):\n",
    "        # Parameter und Eingaben fuer Faltung definieren\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (41)]\n",
    "        stride =\n",
    "        padding =\n",
    "        dilation =\n",
    "        groups =\n",
    "\n",
    "        input_ =\n",
    "        filter_ =\n",
    "\n",
    "        # Faltungsoperation durchfuehren (sollte nicht veraendert werden)\n",
    "        return swap_axes(self.conv2d(input_, filter_,\n",
    "                                     stride=stride,\n",
    "                                     padding=padding,\n",
    "                                     dilation=dilation,\n",
    "                                     groups=groups))\n",
    "\n",
    "# Objekt der Schicht erstellen\n",
    "conv = ConvolutionWithPadding()\n",
    "\n",
    "# exemparische Anwendung (fuer Testzwecke und Verstaendnisexperimente)\n",
    "# siehe DilatedConvolution\n",
    "\n",
    "# Impelementierung ueberpruefen\n",
    "interactive_check('conv_with_padding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 5px\">\n",
    "\n",
    "<a name=\"praktikum3\"></a>\n",
    "<h3 style=\"color: #aa0000;\">Praktikumsaufgabe P6.3: Convolution mit 1x1-Filtern & Gruppen</h3>\n",
    "\n",
    "Leiten Sie anhand systematischer Experimente ab, welche Ableitungen sich ausgehend von den Fehlergradienten am Output $\\dfrac{\\partial E}{\\partial O^{(l)}}$ einer Schicht in Richtung der Filter-Gewichte $W^{(l)}$ und des Inputs $O^{(l-1)}$ bei Verwendung der nachfolgenden Convolutions ergeben.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Folgende Literaturstelle könnte für die Vervollständigung der Lücken hilfreich sein:\n",
    "<ul style=\"margin-bottom: 0px; margin-top: 0px\">\n",
    "    <li>Dumoulin, et. al.: <i>A guide to convolution arithmetic for deep learning</i>, arXiv 2016.&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://arxiv.org/pdf/1603.07285.pdf\" target=\"_blank\">arXiv</a>\n",
    "        </li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie, dass die für die Faltungen realisierten Klassen stets von der nachfolgenden Klasse (`ConvolutionBase`) ableiten sollten - diese Basisklasse untersützt bereits eine Funktion zur Realisierung einer Faltungsoperation (`self.conv2d`) mit allen bekannten Parametern. Es ist daher nicht notwendig, die oben im Notebook verwendeten Funktionen händisch zu erweitern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tui_dl4cv.cnn import ConvolutionBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgende Funktionen werden an verschiedenen Stellen benötigt und untersützen Sie bei der Realisierung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_180(tensor):\n",
    "    \"\"\"Tensor entlang der raeumlichen Dimensionen um 180 Grad drehen\"\"\"\n",
    "    return np.flip(np.flip(tensor, axis=2), axis=3)\n",
    "\n",
    "def swap_axes(tensor, axis1=0, axis2=1):\n",
    "    \"\"\"Zwei Achsen innerhalb eines Tensors tauschen\"\"\"\n",
    "    return np.swapaxes(tensor, axis1=axis1, axis2=axis2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nutzen Sie zudem die vorgesehene Überprüfung zur Validierung Ihrer Impelemtierung.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "<b>Hinweis</b>: Falls einige der Tests fehlschlegen, wird eine entsprechende Fehlermeldung ausgegeben. Beachten Sie, dass die Fehler in '[Optional]' und '[Obligatorisch]' unterteilt sind. Damit Sie die volle Punktzahl erhalten, dürfen keine mit '[Obligatorisch]' gekennzeichneten Fehler auftreten.</div>\n",
    "\n",
    "---\n",
    "**1x1 Convolution mit zunehmender Anzahl an Kanälen:**\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Kanalanzahl Input } n^{(l-1)} = 1\\\\[4mm]\n",
    "\\text{Kanalanzahl Output } n^{(l)} = 2, \\; \\text{Filtergröße } k^{(l)} = 1, \\; \\text{Stride } s^{(l)} = 1, \\; \\text{Padding } p^{(l)} = 0, \\; \\text{Dilation } r^{(l)} = 1, \\; \\text{Groups } g^{(l)} = 1\n",
    "\\end{equation}\n",
    "\n",
    "Beschreiben Sie <u>ganz kurz</u>, wie die Convolution parametriert und durchgeführt werden muss.\n",
    "Untermauern Sie Ihre Argumentationen durch das Einsetzen geeigneter Parameter in nachfolgenden Code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ff0000;\">(Anpassung der Antwort durch Doppelklick hier)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution1x1MoreChannels(ConvolutionBase):\n",
    "    def __init__(self):\n",
    "        # oben definierte Parameter weitergeben, im Nachgang ebenfalls als self.* verfuegbar\n",
    "        super().__init__(\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            dilation=1,\n",
    "            groups=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def backward_input(self, output_tensor_grad):\n",
    "        weight_tensor = self.weight\n",
    "\n",
    "        # Parameter und Eingaben fuer Faltung definieren\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (42)]\n",
    "        stride =\n",
    "        padding =\n",
    "        dilation =\n",
    "        groups =\n",
    "\n",
    "        input_ =\n",
    "        filter_ =\n",
    "\n",
    "        # Faltungsoperation durchfuehren (sollte nicht veraendert werden)\n",
    "        return self.conv2d(input_, filter_,\n",
    "                           stride=stride,\n",
    "                           padding=padding,\n",
    "                           dilation=dilation,\n",
    "                           groups=groups)\n",
    "\n",
    "    def backward_weight(self, output_tensor_grad):\n",
    "        # Parameter und Eingaben fuer Faltung definieren\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (43)]\n",
    "        stride =\n",
    "        padding =\n",
    "        dilation =\n",
    "        groups =\n",
    "\n",
    "        input_ =\n",
    "        filter_ =\n",
    "\n",
    "        # Faltungsoperation durchfuehren (sollte nicht veraendert werden)\n",
    "        return swap_axes(self.conv2d(input_, filter_,\n",
    "                                     stride=stride,\n",
    "                                     padding=padding,\n",
    "                                     dilation=dilation,\n",
    "                                     groups=groups))\n",
    "\n",
    "# Objekt der Schicht erstellen\n",
    "conv = Convolution1x1MoreChannels()\n",
    "\n",
    "# exemparische Anwendung (fuer Testzwecke und Verstaendnisexperimente)\n",
    "# siehe DilatedConvolution\n",
    "\n",
    "# Impelementierung ueberpruefen\n",
    "interactive_check('conv_1x1_more_channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**1x1 Convolution mit Reduktion der Kanalanzahl:**\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Kanalanzahl Input } n^{(l-1)} = 2\\\\[4mm]\n",
    "\\text{Kanalanzahl Output } n^{(l)} = 1, \\; \\text{Filtergröße } k^{(l)} = 1, \\; \\text{Stride } s^{(l)} = 1, \\; \\text{Padding } p^{(l)} = 0, \\; \\text{Dilation } r^{(l)} = 1, \\; \\text{Groups } g^{(l)} = 1\n",
    "\\end{equation}\n",
    "\n",
    "Beschreiben Sie <u>ganz kurz</u>, wie die Convolution parametriert und durchgeführt werden muss.\n",
    "Untermauern Sie Ihre Argumentationen durch das Einsetzen geeigneter Parameter in nachfolgenden Code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ff0000;\">(Anpassung der Antwort durch Doppelklick hier)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution1x1LessChannels(ConvolutionBase):\n",
    "    def __init__(self):\n",
    "        # oben definierte Parameter weitergeben, im Nachgang ebenfalls als self.* verfuegbar\n",
    "        super().__init__(\n",
    "            in_channels=2,\n",
    "            out_channels=1,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            dilation=1,\n",
    "            groups=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def backward_input(self, output_tensor_grad):\n",
    "        weight_tensor = self.weight\n",
    "\n",
    "        # Parameter und Eingaben fuer Faltung definieren\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (44)]\n",
    "        stride =\n",
    "        padding =\n",
    "        dilation =\n",
    "        groups =\n",
    "\n",
    "        input_ =\n",
    "        filter_ =\n",
    "\n",
    "        # Faltungsoperation durchfuehren (sollte nicht veraendert werden)\n",
    "        return self.conv2d(input_, filter_,\n",
    "                           stride=stride,\n",
    "                           padding=padding,\n",
    "                           dilation=dilation,\n",
    "                           groups=groups)\n",
    "\n",
    "    def backward_weight(self, output_tensor_grad):\n",
    "        # Parameter und Eingaben fuer Faltung definieren\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (45)]\n",
    "        stride =\n",
    "        padding =\n",
    "        dilation =\n",
    "        groups =\n",
    "\n",
    "        input_ =\n",
    "        filter_ =\n",
    "\n",
    "        # Faltungsoperation durchfuehren (sollte nicht veraendert werden)\n",
    "        return swap_axes(self.conv2d(input_, filter_,\n",
    "                                     stride=stride,\n",
    "                                     padding=padding,\n",
    "                                     dilation=dilation,\n",
    "                                     groups=groups))\n",
    "\n",
    "# Objekt der Schicht erstellen\n",
    "conv = Convolution1x1LessChannels()\n",
    "\n",
    "# exemparische Anwendung (fuer Testzwecke und Verstaendnisexperimente)\n",
    "# siehe DilatedConvolution\n",
    "\n",
    "# Impelementierung ueberpruefen\n",
    "interactive_check('conv_1x1_less_channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Grouped Convolution:**\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Kanalanzahl Input } n^{(l-1)} = 2\\\\[4mm]\n",
    "\\text{Kanalanzahl Output } n^{(l)} = 4, \\; \\text{Filtergröße } k^{(l)} = 3, \\; \\text{Stride } s^{(l)} = 1, \\; \\text{Padding } p^{(l)} = 1, \\; \\text{Dilation } r^{(l)} = 1, \\; \\text{Groups } g^{(l)} = 2\n",
    "\\end{equation}\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Beachten Sie, dass die Implementierung für die Grouped Convolution anspruchsvoller als die anderen Implementierungen ist. Für beide Gradientenberechnungen ist im Backward Pass ebenfalls eine Grouped Convolution nötig. Jedoch müssen die Gewichte in <code>backward_input</code> bzw. der Input in <code>backward_weight</code> durch <code>np.reshape</code> und <code>swap_axes</code> zuvor entsprechend umstrukturiert werden.</div>\n",
    "\n",
    "Beschreiben Sie <u>ganz kurz</u>, wie die Convolution parametriert und durchgeführt werden muss.\n",
    "Untermauern Sie Ihre Argumentationen durch das Einsetzen geeigneter Parameter in nachfolgenden Code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ff0000;\">(Anpassung der Antwort durch Doppelklick hier)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class GroupedConvolution(ConvolutionBase):\n",
    "    def __init__(self):\n",
    "        # oben definierte Parameter weitergeben, im Nachgang ebenfalls als self.* verfuegbar\n",
    "        super().__init__(\n",
    "            in_channels=2,\n",
    "            out_channels=4,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            dilation=1,\n",
    "            groups=2,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "    def backward_input(self, output_tensor_grad):\n",
    "        weight_tensor = self.weight\n",
    "\n",
    "        # Parameter und Eingaben fuer Faltung definieren\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (46)]\n",
    "        stride =\n",
    "        padding =\n",
    "        dilation =\n",
    "        groups =\n",
    "\n",
    "        input_ =\n",
    "        filter_ =\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Faltungsoperation durchfuehren (sollte nicht veraendert werden)\n",
    "        return self.conv2d(input_, filter_,\n",
    "                           stride=stride,\n",
    "                           padding=padding,\n",
    "                           dilation=dilation,\n",
    "                           groups=groups)\n",
    "\n",
    "    def backward_weight(self, output_tensor_grad):\n",
    "        # Parameter und Eingaben fuer Faltung definieren\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (47)]\n",
    "        stride =\n",
    "        padding =\n",
    "        dilation =\n",
    "        groups =\n",
    "\n",
    "        input_ =\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        filter_ =\n",
    "\n",
    "        # Faltungsoperation durchfuehren (sollte nicht veraendert werden)\n",
    "        result = swap_axes(self.conv2d(input_, filter_,\n",
    "                                       padding=padding,\n",
    "                                       stride=stride,\n",
    "                                       dilation=dilation,\n",
    "                                       groups=groups))\n",
    "        return result\n",
    "\n",
    "# Objekt der Schicht erstellen\n",
    "conv = GroupedConvolution()\n",
    "\n",
    "# exemparische Anwendung (fuer Testzwecke und Verstaendnisexperimente)\n",
    "# siehe DilatedConvolution\n",
    "\n",
    "# Impelementierung ueberpruefen\n",
    "interactive_check('grouped_conv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$_{_\\text{Created for Deep Learning for Computer Vision (DL4CV)}}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a36bc1df758689cab85bd3cddbf19760f70742c7b9e9867a3c5834cb2b9245b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
