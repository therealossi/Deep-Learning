{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 15 - SENet\n",
    "\n",
    "Dieses Notebook thematisiert den Forward und Backward Pass durch einen (SE-)ResNet-v1-Bottleneck-Block.\n",
    "\n",
    "Ziel ist es, den Forward und Backward Pass in PyTorch zu realisieren und die Ergebnisse aus den Übungsunterlagen zu reproduzieren.\n",
    "\n",
    "### Inhaltsverzeichnis\n",
    "- [(d) Implementierung des SE-ResNet-v1-Bottleneck-Blocks in PyTorch](#d)\n",
    "    - [Implementierung des Squeeze-and-Excitation-Blocks](#se-block)\n",
    "    - [Implementierung des Bottleneck-Blocks](#bottleneck-block)\n",
    "    - [Block erstellen und Forward und Backward Propagation anwenden](#se-anwendung)\n",
    "- [Reproduktion der Ergebnisse aus Aufgabe 14](#reproduktion-a14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 5px\">\n",
    "\n",
    "### Vorbereitung\n",
    "Der Übersicht halber sind einige Funktionalitäten in ein separates Paket ausgelagert. Grundvoraussetzung für deren Verwendung ist, dass Sie das Paket `tui-dl4cv` <font color=\"#aa0000\">installieren bzw. aktualisieren</font> und anschließend importieren.\n",
    "\n",
    "Für die Installation stehen Ihnen zwei mögliche Wege zur Verfügung.\n",
    "\n",
    "**(1) Installation direkt in diesem Notebook:**\n",
    "Führen Sie den nachfolgenden Code-Block aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(f\"Automatically install package for '{sys.executable}'\")\n",
    "!{sys.executable} -m pip install tui-dl4cv \\\n",
    "    --extra-index-url \"https://2022ws:xXCgQHZxxeNYchgryN7e@nikrgl.informatik.tu-ilmenau.de/api/v4/projects/1730/packages/pypi/simple\" \\\n",
    "    --no-cache --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ODER\n",
    "\n",
    "**(2) Manuelle Installation über die Konsole:**\n",
    "Öffnen Sie eine Konsole (\"Anaconda Prompt\" unter Windows) und führen Sie folgenden Befehl aus:\n",
    "```text\n",
    "pip install tui-dl4cv --extra-index-url \"https://2022ws:xXCgQHZxxeNYchgryN7e@nikrgl.informatik.tu-ilmenau.de/api/v4/projects/1730/packages/pypi/simple\" --no-cache --upgrade\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Führen Sie abschließend folgenden Code-Block aus, um das Paket verwenden zu können.**\n",
    "Während der Bearbeitung können Sie nun Ihre Ergebnisse mithilfe der Funktion `interactive_check` überprüfen. Die Funktionsaufrufe sind bereits an den entsprechenden Stellen im Notebook enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tui_dl4cv.seresnet\n",
    "\n",
    "# noetige Erweiterung, damit Variablen aus diesem Notebook automatisch ueberprueft werden koennen\n",
    "def interactive_check(name, **kwargs):\n",
    "    tui_dl4cv.seresnet.interactive_check(name, globals(), **kwargs)\n",
    "\n",
    "from tui_dl4cv.seresnet import apply_block_weights\n",
    "from tui_dl4cv.seresnet import print_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 5px\">\n",
    "\n",
    "<a name=\"d\"></a>\n",
    "### (d) Vollziehen Sie die Backpropagation durch den SE-ResNet-v1-Bottleneck-Block anhand einer PyTorch-Implementierung nach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Pakete importieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name=\"se-block\"></a>\n",
    "*Squeeze-and-Excitation-Block implementieren:*\n",
    "\n",
    "Zunächst soll eine PyTorch-Klasse für den Squeeze-and-Excitation-Block implementiert werden.\n",
    "\n",
    "Im Squeeze-and-Excitation-Block wird zunächst mittels Global Average Pooling die Räumlichkeit entfernt (Squeeze-Operation). Anschließend werden mithilfe von zwei Convolutions (Excitation-Operation) Wichtungsfaktoren für jeden Kanal berechnet. In der Excitation-Operation wird die Kanalanzahl dabei zuerst um den Faktor `r` reduziert, um eine *fokusierte Anregunng* zu bestimmen, und anschließend wieder auf die ursprüngliche Kanalanzahl zurückprojiziert.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Folgende PyTorch-Definitionen könnten für die Vervollständigung der Lücken hilfreich sein:\n",
    "    <ul style=\"margin-bottom: 0px\">\n",
    "        <li><code style=\"background-color: #FAEAEA;\">torch.nn.Module</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Module.html\" target=\"_blank\">PyTorch-Dokumentation</a>\n",
    "        </li>\n",
    "        <li><code style=\"background-color: #FAEAEA;\">torch.nn.Conv2d</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\" target=\"_blank\">PyTorch-Dokumentation</a>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeAndExcitationBlock(torch.nn.Module):\n",
    "    def __init__(self, n_channels, r=16):\n",
    "        super().__init__()\n",
    "\n",
    "        # Schichten anlegen\n",
    "        self.conv1 =     # bitte Code ergaenzen <---------------- [Luecke (1)]\n",
    "        self.conv2 =     # bitte Code ergaenzen <---------------- [Luecke (2)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Kopieren des Inputs, damit die Gradienten der einzelnen Pfade\n",
    "        # getrennt voneinander ausgegeben werden koennen\n",
    "        x_skip = x.clone()\n",
    "        x_se = x.clone()\n",
    "\n",
    "        # Squeeze (Global Average Pooling = Mittelwert ueber Dim. 2 und 3)\n",
    "        gap_out =     # bitte Code ergaenzen <---------------- [Luecke (3)]\n",
    "\n",
    "        # Excitation\n",
    "        conv1_act =     # bitte Code ergaenzen <---------------- [Luecke (4)]\n",
    "        conv1_out =     # bitte Code ergaenzen <---------------- [Luecke (5)]\n",
    "        conv2_act =     # bitte Code ergaenzen <---------------- [Luecke (6)]\n",
    "        conv2_out =     # bitte Code ergaenzen <---------------- [Luecke (7)]\n",
    "\n",
    "        # Skalierung der Eingangswerte\n",
    "        y =     # bitte Code ergaenzen <---------------- [Luecke (8)]\n",
    "\n",
    "        # Ergebnisse fuer Forward Pass ausgeben\n",
    "        print_tensors((gap_out, conv1_act, conv1_out, conv2_act, conv2_out, y),\n",
    "                      ('se_gap_out', 'se_conv1_act', 'se_conv1_out', 'se_conv2_act', 'se_conv2_out', 'se_y'))\n",
    "\n",
    "        # Ergebnisse fuer Backward Pass ausgeben\n",
    "        # Realisierung ueber Hooks\n",
    "        # hier: nur Gradienten des Vordrucks\n",
    "        gap_out.register_hook(lambda grad: print_tensors(grad, 'se_gap_out.grad'))\n",
    "        conv2_out.register_hook(lambda grad: print_tensors(grad, 'se_conv2_out.grad'))\n",
    "        x_skip.register_hook(lambda grad: print_tensors(grad, 'se_x_skip.grad'))\n",
    "        x_se.register_hook(lambda grad: print_tensors(grad, 'se_x_se.grad'))\n",
    "        x.register_hook(lambda grad: print_tensors(grad, 'se_x.grad'))\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name=\"bottleneck-block\"></a>\n",
    "*(SE-)ResNet-v1-Bottleneck-Block implementieren:*\n",
    "\n",
    "Im nächsten Schritt soll der (SE-)ResNet-v1-Bottleneck-Block implementiert werden.\n",
    "Die Verwendung des Squeeze-and-Excitation-Blocks soll dabei optional sein, damit später die Ergebnisse für beide Fälle reproduziert werden können.\n",
    "\n",
    "Im Bottleneck-Block wird die Anzahl der Input Feature Maps (`n_channels_in`) zunächst mithilfe einer ersten 1x1 Convolution auf `n_channels` reduziert. Anschließend folgt eine 3x3 Convolution, bei der die Kanalanzahl unverändert bleibt. Abschließend wird die Anzahl der Kanäle mithilfe einer weiteren 1x1 Convolution um den Faktor 4 expandiert.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #EAF2F8; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Beachten Sie, dass in der nachfolgenden Implementierung bewusst auf Batch Normalization verzichtet wird, um Ergebnisgleichheit mit der Rechenaufgabe zu erreichen. Die entsprechenden Stellen sind daher auskommentiert. Weiterhin unterstützt die Implementierung kein Downsampling. Die Skip Connection ist daher immer frei von zusätzlichen Operationen. Beide Aspekte werden in der nächsten Übungsaufgabe aufgegriffen.\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Folgende PyTorch-Definitionen könnten für die Vervollständigung der Lücken hilfreich sein:\n",
    "    <ul style=\"margin-bottom: 0px\">\n",
    "        <li><code style=\"background-color: #FAEAEA;\">torch.nn.Module</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Module.html\" target=\"_blank\">PyTorch-Dokumentation</a>\n",
    "        </li>\n",
    "        <li><code style=\"background-color: #FAEAEA;\">torch.nn.Identity</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Identity.html\" target=\"_blank\">PyTorch-Dokumentation</a>\n",
    "        </li>\n",
    "        <li><code style=\"background-color: #FAEAEA;\">torch.nn.Conv2d</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\" target=\"_blank\">PyTorch-Dokumentation</a>\n",
    "        </li>\n",
    "        <li><code style=\"background-color: #FAEAEA;\">torch.nn.BatchNorm2d</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html\" target=\"_blank\">PyTorch-Dokumentation</a>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckBlock(torch.nn.Module):\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, n_channels_in, n_channels, r_se=None, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # keine Unterstuetzung fuer Downsampling bzw. Aenderung der Kanalanzahl\n",
    "        assert stride == 1\n",
    "        self.skip = torch.nn.Identity()\n",
    "\n",
    "        # Schichten anlegen\n",
    "        self.conv1 =     # bitte Code ergaenzen <---------------- [Luecke (9)]\n",
    "        # self.conv1_bn = torch.nn.BatchNorm2d(n_channels)\n",
    "\n",
    "        self.conv2 =     # bitte Code ergaenzen <---------------- [Luecke (10)]\n",
    "        # self.conv2_bn = torch.nn.BatchNorm2d(n_channels)\n",
    "\n",
    "        self.conv3 =     # bitte Code ergaenzen <---------------- [Luecke (11)]\n",
    "        # self.conv3_bn = torch.nn.BatchNorm2d(channels_out)\n",
    "\n",
    "        # Squeeze-and-Excitation-Block\n",
    "        if r_se is not None:\n",
    "            # SE soll verwendet werden\n",
    "            self.se =     # bitte Code ergaenzen <---------------- [Luecke (12)]\n",
    "        else:\n",
    "            self.se = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Kopieren des Inputs, damit die Gradienten der einzelnen Pfade\n",
    "        # getrennt voneinander ausgegeben werden koennen\n",
    "        x_skip = x.clone()\n",
    "        x_res = x.clone()\n",
    "\n",
    "        # Residuum\n",
    "        conv1_act =     # bitte Code ergaenzen <---------------- [Luecke (13)]\n",
    "        # conv1_act = self.conv1_bn(conv1_act)\n",
    "        conv1_out =     # bitte Code ergaenzen <---------------- [Luecke (14)]\n",
    "\n",
    "        conv2_act =     # bitte Code ergaenzen <---------------- [Luecke (15)]\n",
    "        # conv2_act = self.conv2_bn(conv2_act)\n",
    "        conv2_out =     # bitte Code ergaenzen <---------------- [Luecke (16)]\n",
    "\n",
    "        conv3_act =     # bitte Code ergaenzen <---------------- [Luecke (17)]\n",
    "        # conv3_act = self.conv3_bn(conv3_act)\n",
    "\n",
    "        # Ergebnisse fuer Forward Pass ausgeben\n",
    "        print_tensors((conv1_act, conv1_out, conv2_act, conv2_out, conv3_act),\n",
    "                      ('conv1_act', 'conv1_out', 'conv2_act', 'conv2_out', 'conv3_act'))\n",
    "\n",
    "        # SE\n",
    "        if self.se is not None:\n",
    "            res =     # bitte Code ergaenzen <---------------- [Luecke (18)]\n",
    "        else:\n",
    "            res =     # bitte Code ergaenzen <---------------- [Luecke (19)]\n",
    "\n",
    "        # Skip Connection\n",
    "        skip = self.skip(x_skip)\n",
    "\n",
    "        # beide Zweige zusammenfuehren\n",
    "        z =     # bitte Code ergaenzen <---------------- [Luecke (20)]\n",
    "        y =     # bitte Code ergaenzen <---------------- [Luecke (21)]\n",
    "\n",
    "        # Ergebnisse fuer Forward Pass ausgeben\n",
    "        print_tensors((res, z, y), ('res', 'z', 'y'))\n",
    "\n",
    "        # Ergebnisse fuer Backward Pass ausgeben\n",
    "        # Realisierung ueber Hooks\n",
    "        # hier: nur Gradienten des Vordrucks\n",
    "        z.register_hook(lambda grad: print_tensors(grad, 'z.grad'))\n",
    "        res.register_hook(lambda grad: print_tensors(grad, 'res.grad'))\n",
    "        x_skip.register_hook(lambda grad: print_tensors(grad, 'x_skip.grad'))\n",
    "        x_res.register_hook(lambda grad: print_tensors(grad, 'x_res.grad'))\n",
    "        x.register_hook(lambda grad: print_tensors(grad, 'x.grad'))\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name=\"se-anwendung\"></a>\n",
    "*SE-ResNet-v1-Bottleneck-Block erstellen und Gewichte laden:*\n",
    "\n",
    "Der Übersicht halber sind die Gewichte bereits im `tui-dl4cv`-Paket definiert und können über die Funktion `apply_block_weights` geladen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block-Objekt erzeugen\n",
    "block = BottleneckBlock(\n",
    "    n_channels_in=8,\n",
    "    n_channels=2,\n",
    "    r_se=4\n",
    ")\n",
    "\n",
    "# Gewichte laden (nur fuer oben definierten Block)\n",
    "apply_block_weights(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Forward Pass:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Eingabe definieren\n",
    "x = torch.tensor(\n",
    "    [[[[1, 1, 0],\n",
    "       [0, 0, 0],\n",
    "       [0, 1, 0]],\n",
    "      [[1, 0, 0],\n",
    "       [1, 1, 0],\n",
    "       [0, 1, 0]],\n",
    "      [[1, 0, 0],\n",
    "       [0, 1, 0],\n",
    "       [0, 1, 0]],\n",
    "      [[1, 1, 0],\n",
    "       [0, 1, 2],\n",
    "       [0, 0, 0]],\n",
    "      [[3, 0, 2],\n",
    "       [0, 0, 1],\n",
    "       [0, 1, 0]],\n",
    "      [[0, 0, 0],\n",
    "       [0, 0, 0],\n",
    "       [1, 0, 1]],\n",
    "      [[1, 0, 0],\n",
    "       [0, 3, 0],\n",
    "       [0, 1, 0]],\n",
    "      [[0, 0, 0],\n",
    "       [0, 0, 2],\n",
    "       [1, 0, 1]]]],\n",
    "    dtype=torch.float32, requires_grad=True\n",
    ")\n",
    "\n",
    "# Forward Propagation\n",
    "y = block(x)\n",
    "\n",
    "# Ergebnis ueberpruefen\n",
    "interactive_check('seresnet_forward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "    <br>\n",
    "    <i>Ausgaben bei korrekter Implementierung:</i>\n",
    "    <br>\n",
    "    <code style=\"padding: 0\">\n",
    "conv1_act:\n",
    "[[[[ 1.  1.  2.]\n",
    "   [ 2. -9.  5.]\n",
    "   [ 3. -1.  3.]]\n",
    "  [[ 2. -3.  2.]\n",
    "   [ 0.  3.  1.]\n",
    "   [ 1.  1.  1.]]]]\n",
    "conv1_out:\n",
    "[[[[1. 1. 2.]\n",
    "   [2. 0. 5.]\n",
    "   [3. 0. 3.]]\n",
    "  [[2. 0. 2.]\n",
    "   [0. 3. 1.]\n",
    "   [1. 1. 1.]]]]\n",
    "conv2_act:\n",
    "[[[[ -1.  -5.  -9.]\n",
    "   [ -1.   0.  -6.]\n",
    "   [  9. -18.  10.]]\n",
    "  [[ -5.  -1.  -1.]\n",
    "   [ -1.  -4.  10.]\n",
    "   [ 12. -14.   8.]]]]\n",
    "conv2_out:\n",
    "[[[[ 0.  0.  0.]\n",
    "   [ 0.  0.  0.]\n",
    "   [ 9.  0. 10.]]\n",
    "  [[ 0.  0.  0.]\n",
    "   [ 0.  0. 10.]\n",
    "   [12.  0.  8.]]]]\n",
    "conv3_act:\n",
    "[[[[  0.   0.   0.]\n",
    "   [  0.   0.  20.]\n",
    "   [-30.   0. -44.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0. -10.]\n",
    "   [ 15.   0.  22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  30.]\n",
    "   [ 36.   0.  24.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  10.]\n",
    "   [-15.   0. -22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0. -20.]\n",
    "   [ 30.   0.  44.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.   0.]\n",
    "   [  0.   0.   0.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  20.]\n",
    "   [ 51.   0.  46.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  50.]\n",
    "   [ 87.   0.  70.]]]]\n",
    "se_gap_out:\n",
    "[[[[-6.]]\n",
    "  [[ 3.]]\n",
    "  [[10.]]\n",
    "  [[-3.]]\n",
    "  [[ 6.]]\n",
    "  [[ 0.]]\n",
    "  [[13.]]\n",
    "  [[23.]]]]\n",
    "se_conv1_act:\n",
    "[[[[1.]]\n",
    "  [[6.]]]]\n",
    "se_conv1_out:\n",
    "[[[[1.]]\n",
    "  [[6.]]]]\n",
    "se_conv2_act:\n",
    "[[[[  0.]]\n",
    "  [[ 20.]]\n",
    "  [[ 12.]]\n",
    "  [[ 13.]]\n",
    "  [[  0.]]\n",
    "  [[-13.]]\n",
    "  [[ 19.]]\n",
    "  [[-18.]]]]\n",
    "se_conv2_out:\n",
    "[[[[0.5]]\n",
    "  [[1. ]]\n",
    "  [[1. ]]\n",
    "  [[1. ]]\n",
    "  [[0.5]]\n",
    "  [[0. ]]\n",
    "  [[1. ]]\n",
    "  [[0. ]]]]\n",
    "se_y:\n",
    "[[[[  0.   0.   0.]\n",
    "   [  0.   0.  10.]\n",
    "   [-15.   0. -22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0. -10.]\n",
    "   [ 15.   0.  22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  30.]\n",
    "   [ 36.   0.  24.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  10.]\n",
    "   [-15.   0. -22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0. -10.]\n",
    "   [ 15.   0.  22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.   0.]\n",
    "   [  0.   0.   0.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  20.]\n",
    "   [ 51.   0.  46.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.   0.]\n",
    "   [  0.   0.   0.]]]]\n",
    "res:\n",
    "[[[[  0.   0.   0.]\n",
    "   [  0.   0.  10.]\n",
    "   [-15.   0. -22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0. -10.]\n",
    "   [ 15.   0.  22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  30.]\n",
    "   [ 36.   0.  24.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  10.]\n",
    "   [-15.   0. -22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0. -10.]\n",
    "   [ 15.   0.  22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.   0.]\n",
    "   [  0.   0.   0.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  20.]\n",
    "   [ 51.   0.  46.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.   0.]\n",
    "   [  0.   0.   0.]]]]\n",
    "z:\n",
    "[[[[  1.   1.   0.]\n",
    "   [  0.   0.  10.]\n",
    "   [-15.   1. -22.]]\n",
    "  [[  1.   0.   0.]\n",
    "   [  1.   1. -10.]\n",
    "   [ 15.   1.  22.]]\n",
    "  [[  1.   0.   0.]\n",
    "   [  0.   1.  30.]\n",
    "   [ 36.   1.  24.]]\n",
    "  [[  1.   1.   0.]\n",
    "   [  0.   1.  12.]\n",
    "   [-15.   0. -22.]]\n",
    "  [[  3.   0.   2.]\n",
    "   [  0.   0.  -9.]\n",
    "   [ 15.   1.  22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.   0.]\n",
    "   [  1.   0.   1.]]\n",
    "  [[  1.   0.   0.]\n",
    "   [  0.   3.  20.]\n",
    "   [ 51.   1.  46.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.   2.]\n",
    "   [  1.   0.   1.]]]]\n",
    "y:\n",
    "[[[[ 1.  1.  0.]\n",
    "   [ 0.  0. 10.]\n",
    "   [ 0.  1.  0.]]\n",
    "  [[ 1.  0.  0.]\n",
    "   [ 1.  1.  0.]\n",
    "   [15.  1. 22.]]\n",
    "  [[ 1.  0.  0.]\n",
    "   [ 0.  1. 30.]\n",
    "   [36.  1. 24.]]\n",
    "  [[ 1.  1.  0.]\n",
    "   [ 0.  1. 12.]\n",
    "   [ 0.  0.  0.]]\n",
    "  [[ 3.  0.  2.]\n",
    "   [ 0.  0.  0.]\n",
    "   [15.  1. 22.]]\n",
    "  [[ 0.  0.  0.]\n",
    "   [ 0.  0.  0.]\n",
    "   [ 1.  0.  1.]]\n",
    "  [[ 1.  0.  0.]\n",
    "   [ 0.  3. 20.]\n",
    "   [51.  1. 46.]]\n",
    "  [[ 0.  0.  0.]\n",
    "   [ 0.  0.  2.]\n",
    "   [ 1.  0.  1.]]]]\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Backward Pass:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Gradienten definieren\n",
    "y_grad = torch.ones(y.shape)\n",
    "\n",
    "# Backpass durchfuehren\n",
    "y.backward(y_grad)\n",
    "\n",
    "# Ergebnis ueberpruefen\n",
    "interactive_check('seresnet_backward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "    <br>\n",
    "    <i>Augaben bei korrekter Implementierung:</i>\n",
    "    <br>\n",
    "    <code style=\"padding: 0\">\n",
    "z.grad:\n",
    "[[[[1. 1. 0.]\n",
    "   [0. 0. 1.]\n",
    "   [0. 1. 0.]]\n",
    "  [[1. 0. 0.]\n",
    "   [1. 1. 0.]\n",
    "   [1. 1. 1.]]\n",
    "  [[1. 0. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [1. 1. 1.]]\n",
    "  [[1. 1. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [0. 0. 0.]]\n",
    "  [[1. 0. 1.]\n",
    "   [0. 0. 0.]\n",
    "   [1. 1. 1.]]\n",
    "  [[0. 0. 0.]\n",
    "   [0. 0. 0.]\n",
    "   [1. 0. 1.]]\n",
    "  [[1. 0. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [1. 1. 1.]]\n",
    "  [[0. 0. 0.]\n",
    "   [0. 0. 1.]\n",
    "   [1. 0. 1.]]]]\n",
    "res.grad:\n",
    "[[[[1. 1. 0.]\n",
    "   [0. 0. 1.]\n",
    "   [0. 1. 0.]]\n",
    "  [[1. 0. 0.]\n",
    "   [1. 1. 0.]\n",
    "   [1. 1. 1.]]\n",
    "  [[1. 0. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [1. 1. 1.]]\n",
    "  [[1. 1. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [0. 0. 0.]]\n",
    "  [[1. 0. 1.]\n",
    "   [0. 0. 0.]\n",
    "   [1. 1. 1.]]\n",
    "  [[0. 0. 0.]\n",
    "   [0. 0. 0.]\n",
    "   [1. 0. 1.]]\n",
    "  [[1. 0. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [1. 1. 1.]]\n",
    "  [[0. 0. 0.]\n",
    "   [0. 0. 1.]\n",
    "   [1. 0. 1.]]]]\n",
    "se_conv2_out.grad:\n",
    "[[[[ 20.]]\n",
    "  [[ 37.]]\n",
    "  [[ 90.]]\n",
    "  [[ 10.]]\n",
    "  [[ 74.]]\n",
    "  [[  0.]]\n",
    "  [[117.]]\n",
    "  [[207.]]]]\n",
    "se_gap_out.grad:\n",
    "[[[[ -44.99]]\n",
    "  [[  89.98]]\n",
    "  [[ -25.  ]]\n",
    "  [[ -25.  ]]\n",
    "  [[-119.99]]\n",
    "  [[   0.  ]]\n",
    "  [[  45.  ]]\n",
    "  [[ -10.  ]]]]\n",
    "se_x_se.grad:\n",
    "[[[[ -5.    -5.    -5.  ]\n",
    "   [ -5.    -5.    -5.  ]\n",
    "   [ -5.    -5.    -5.  ]]\n",
    "  [[ 10.    10.    10.  ]\n",
    "   [ 10.    10.    10.  ]\n",
    "   [ 10.    10.    10.  ]]\n",
    "  [[ -2.78  -2.78  -2.78]\n",
    "   [ -2.78  -2.78  -2.78]\n",
    "   [ -2.78  -2.78  -2.78]]\n",
    "  [[ -2.78  -2.78  -2.78]\n",
    "   [ -2.78  -2.78  -2.78]\n",
    "   [ -2.78  -2.78  -2.78]]\n",
    "  [[-13.33 -13.33 -13.33]\n",
    "   [-13.33 -13.33 -13.33]\n",
    "   [-13.33 -13.33 -13.33]]\n",
    "  [[  0.     0.     0.  ]\n",
    "   [  0.     0.     0.  ]\n",
    "   [  0.     0.     0.  ]]\n",
    "  [[  5.     5.     5.  ]\n",
    "   [  5.     5.     5.  ]\n",
    "   [  5.     5.     5.  ]]\n",
    "  [[ -1.11  -1.11  -1.11]\n",
    "   [ -1.11  -1.11  -1.11]\n",
    "   [ -1.11  -1.11  -1.11]]]]\n",
    "se_x_skip.grad:\n",
    "[[[[0.5 0.5 0. ]\n",
    "   [0.  0.  0.5]\n",
    "   [0.  0.5 0. ]]\n",
    "  [[1.  0.  0. ]\n",
    "   [1.  1.  0. ]\n",
    "   [1.  1.  1. ]]\n",
    "  [[1.  0.  0. ]\n",
    "   [0.  1.  1. ]\n",
    "   [1.  1.  1. ]]\n",
    "  [[1.  1.  0. ]\n",
    "   [0.  1.  1. ]\n",
    "   [0.  0.  0. ]]\n",
    "  [[0.5 0.  0.5]\n",
    "   [0.  0.  0. ]\n",
    "   [0.5 0.5 0.5]]\n",
    "  [[0.  0.  0. ]\n",
    "   [0.  0.  0. ]\n",
    "   [0.  0.  0. ]]\n",
    "  [[1.  0.  0. ]\n",
    "   [0.  1.  1. ]\n",
    "   [1.  1.  1. ]]\n",
    "  [[0.  0.  0. ]\n",
    "   [0.  0.  0. ]\n",
    "   [0.  0.  0. ]]]]\n",
    "se_x.grad:\n",
    "[[[[ -4.5   -4.5   -5.  ]\n",
    "   [ -5.    -5.    -4.5 ]\n",
    "   [ -5.    -4.5   -5.  ]]\n",
    "  [[ 11.    10.    10.  ]\n",
    "   [ 11.    11.    10.  ]\n",
    "   [ 11.    11.    11.  ]]\n",
    "  [[ -1.78  -2.78  -2.78]\n",
    "   [ -2.78  -1.78  -1.78]\n",
    "   [ -1.78  -1.78  -1.78]]\n",
    "  [[ -1.78  -1.78  -2.78]\n",
    "   [ -2.78  -1.78  -1.78]\n",
    "   [ -2.78  -2.78  -2.78]]\n",
    "  [[-12.83 -13.33 -12.83]\n",
    "   [-13.33 -13.33 -13.33]\n",
    "   [-12.83 -12.83 -12.83]]\n",
    "  [[  0.     0.     0.  ]\n",
    "   [  0.     0.     0.  ]\n",
    "   [  0.     0.     0.  ]]\n",
    "  [[  6.     5.     5.  ]\n",
    "   [  5.     6.     6.  ]\n",
    "   [  6.     6.     6.  ]]\n",
    "  [[ -1.11  -1.11  -1.11]\n",
    "   [ -1.11  -1.11  -1.11]\n",
    "   [ -1.11  -1.11  -1.11]]]]\n",
    "x_res.grad:\n",
    "[[[[   0.      7.      0.  ]\n",
    "   [  17.99  -45.96   21.01]\n",
    "   [  27.     59.97   20.  ]]\n",
    "  [[   0.     14.01    0.  ]\n",
    "   [  35.97    0.     78.  ]\n",
    "   [  18.03    0.      4.02]]\n",
    "  [[   0.    -14.01    0.  ]\n",
    "   [ -35.97   22.98  -69.01]\n",
    "   [ -27.02  -29.98  -13.01]]\n",
    "  [[   0.      0.      0.  ]\n",
    "   [   0.    -22.98   -8.99]\n",
    "   [   8.99   29.98    8.99]]\n",
    "  [[   0.      7.      0.  ]\n",
    "   [  17.99   22.98   47.99]\n",
    "   [   0.02  -29.98   -6.98]]\n",
    "  [[   0.      7.      0.  ]\n",
    "   [  17.99    0.     39.  ]\n",
    "   [   9.01    0.      2.01]]\n",
    "  [[   0.    -21.01    0.  ]\n",
    "   [ -53.96   22.98 -108.01]\n",
    "   [ -36.03  -29.98  -15.02]]\n",
    "  [[   0.     14.01    0.  ]\n",
    "   [  35.97   22.98   86.99]\n",
    "   [   9.03  -29.98   -4.97]]]]\n",
    "x_skip.grad:\n",
    "[[[[1. 1. 0.]\n",
    "   [0. 0. 1.]\n",
    "   [0. 1. 0.]]\n",
    "  [[1. 0. 0.]\n",
    "   [1. 1. 0.]\n",
    "   [1. 1. 1.]]\n",
    "  [[1. 0. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [1. 1. 1.]]\n",
    "  [[1. 1. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [0. 0. 0.]]\n",
    "  [[1. 0. 1.]\n",
    "   [0. 0. 0.]\n",
    "   [1. 1. 1.]]\n",
    "  [[0. 0. 0.]\n",
    "   [0. 0. 0.]\n",
    "   [1. 0. 1.]]\n",
    "  [[1. 0. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [1. 1. 1.]]\n",
    "  [[0. 0. 0.]\n",
    "   [0. 0. 1.]\n",
    "   [1. 0. 1.]]]]\n",
    "x.grad:\n",
    "[[[[   1.      8.      0.  ]\n",
    "   [  17.99  -45.96   22.01]\n",
    "   [  27.     60.97   20.  ]]\n",
    "  [[   1.     14.01    0.  ]\n",
    "   [  36.97    1.     78.  ]\n",
    "   [  19.03    1.      5.02]]\n",
    "  [[   1.    -14.01    0.  ]\n",
    "   [ -35.97   23.98  -68.01]\n",
    "   [ -26.02  -28.98  -12.01]]\n",
    "  [[   1.      1.      0.  ]\n",
    "   [   0.    -21.98   -7.99]\n",
    "   [   8.99   29.98    8.99]]\n",
    "  [[   1.      7.      1.  ]\n",
    "   [  17.99   22.98   47.99]\n",
    "   [   1.02  -28.98   -5.98]]\n",
    "  [[   0.      7.      0.  ]\n",
    "   [  17.99    0.     39.  ]\n",
    "   [  10.01    0.      3.01]]\n",
    "  [[   1.    -21.01    0.  ]\n",
    "   [ -53.96   23.98 -107.01]\n",
    "   [ -35.03  -28.98  -14.02]]\n",
    "  [[   0.     14.01    0.  ]\n",
    "   [  35.97   22.98   87.99]\n",
    "   [  10.03  -29.98   -3.97]]]]\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 5px\">\n",
    "\n",
    "<a name=\"reproduktion-a14\"></a>\n",
    "### Die Implementierung ermöglicht es ebenfalls, die Ergebnisse von Übungsaufgabe 14 zu reproduzieren.\n",
    "\n",
    "---\n",
    "\n",
    "*ResNet-v1-Bottleneck-Block erstellen und Gewichte laden:*\n",
    "\n",
    "Der Übersicht halber sind die Gewichte bereits im `tui-dl4cv`-Paket definiert und können über die Funktion `apply_block_weights` geladen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block-Objekt erzeugen\n",
    "block = BottleneckBlock(\n",
    "    n_channels_in=8,\n",
    "    n_channels=2,\n",
    "    r_se=None    # kein SE verwenden\n",
    ")\n",
    "\n",
    "# Gewichte laden (nur fuer oben definierten Block)\n",
    "apply_block_weights(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Forward Pass:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Eingabe definieren\n",
    "x = torch.tensor(\n",
    "    [[[[1, 1, 0],\n",
    "       [0, 0, 0],\n",
    "       [0, 1, 0]],\n",
    "      [[1, 0, 0],\n",
    "       [1, 1, 0],\n",
    "       [0, 1, 0]],\n",
    "      [[1, 0, 0],\n",
    "       [0, 1, 0],\n",
    "       [0, 1, 0]],\n",
    "      [[1, 1, 0],\n",
    "       [0, 1, 2],\n",
    "       [0, 0, 0]],\n",
    "      [[3, 0, 2],\n",
    "       [0, 0, 1],\n",
    "       [0, 1, 0]],\n",
    "      [[0, 0, 0],\n",
    "       [0, 0, 0],\n",
    "       [1, 0, 1]],\n",
    "      [[1, 0, 0],\n",
    "       [0, 3, 0],\n",
    "       [0, 1, 0]],\n",
    "      [[0, 0, 0],\n",
    "       [0, 0, 2],\n",
    "       [1, 0, 1]]]],\n",
    "    dtype=torch.float32, requires_grad=True\n",
    ")\n",
    "\n",
    "# Forward Propagation\n",
    "y = block(x)\n",
    "\n",
    "# Ergebnis ueberpruefen\n",
    "interactive_check('resnet_forward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "    <br>\n",
    "    <i>Ausgaben bei korrekter Implementierung:</i>\n",
    "    <br>\n",
    "    <code style=\"padding: 0\">\n",
    "conv1_act:\n",
    "[[[[ 1.  1.  2.]\n",
    "   [ 2. -9.  5.]\n",
    "   [ 3. -1.  3.]]\n",
    "  [[ 2. -3.  2.]\n",
    "   [ 0.  3.  1.]\n",
    "   [ 1.  1.  1.]]]]\n",
    "conv1_out:\n",
    "[[[[1. 1. 2.]\n",
    "   [2. 0. 5.]\n",
    "   [3. 0. 3.]]\n",
    "  [[2. 0. 2.]\n",
    "   [0. 3. 1.]\n",
    "   [1. 1. 1.]]]]\n",
    "conv2_act:\n",
    "[[[[ -1.  -5.  -9.]\n",
    "   [ -1.   0.  -6.]\n",
    "   [  9. -18.  10.]]\n",
    "  [[ -5.  -1.  -1.]\n",
    "   [ -1.  -4.  10.]\n",
    "   [ 12. -14.   8.]]]]\n",
    "conv2_out:\n",
    "[[[[ 0.  0.  0.]\n",
    "   [ 0.  0.  0.]\n",
    "   [ 9.  0. 10.]]\n",
    "  [[ 0.  0.  0.]\n",
    "   [ 0.  0. 10.]\n",
    "   [12.  0.  8.]]]]\n",
    "conv3_act:\n",
    "[[[[  0.   0.   0.]\n",
    "   [  0.   0.  20.]\n",
    "   [-30.   0. -44.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0. -10.]\n",
    "   [ 15.   0.  22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  30.]\n",
    "   [ 36.   0.  24.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  10.]\n",
    "   [-15.   0. -22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0. -20.]\n",
    "   [ 30.   0.  44.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.   0.]\n",
    "   [  0.   0.   0.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  20.]\n",
    "   [ 51.   0.  46.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  50.]\n",
    "   [ 87.   0.  70.]]]]\n",
    "res:\n",
    "[[[[  0.   0.   0.]\n",
    "   [  0.   0.  20.]\n",
    "   [-30.   0. -44.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0. -10.]\n",
    "   [ 15.   0.  22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  30.]\n",
    "   [ 36.   0.  24.]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  10.]\n",
    "   [-15.   0. -22.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0. -20.]\n",
    "   [ 30.   0.  44.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.   0.]\n",
    "   [  0.   0.   0.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  20.]\n",
    "   [ 51.   0.  46.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  50.]\n",
    "   [ 87.   0.  70.]]]]\n",
    "z:\n",
    "[[[[  1.   1.   0.]\n",
    "   [  0.   0.  20.]\n",
    "   [-30.   1. -44.]]\n",
    "  [[  1.   0.   0.]\n",
    "   [  1.   1. -10.]\n",
    "   [ 15.   1.  22.]]\n",
    "  [[  1.   0.   0.]\n",
    "   [  0.   1.  30.]\n",
    "   [ 36.   1.  24.]]\n",
    "  [[  1.   1.   0.]\n",
    "   [  0.   1.  12.]\n",
    "   [-15.   0. -22.]]\n",
    "  [[  3.   0.   2.]\n",
    "   [  0.   0. -19.]\n",
    "   [ 30.   1.  44.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.   0.]\n",
    "   [  1.   0.   1.]]\n",
    "  [[  1.   0.   0.]\n",
    "   [  0.   3.  20.]\n",
    "   [ 51.   1.  46.]]\n",
    "  [[  0.   0.   0.]\n",
    "   [  0.   0.  52.]\n",
    "   [ 88.   0.  71.]]]]\n",
    "y:\n",
    "[[[[ 1.  1.  0.]\n",
    "   [ 0.  0. 20.]\n",
    "   [ 0.  1.  0.]]\n",
    "  [[ 1.  0.  0.]\n",
    "   [ 1.  1.  0.]\n",
    "   [15.  1. 22.]]\n",
    "  [[ 1.  0.  0.]\n",
    "   [ 0.  1. 30.]\n",
    "   [36.  1. 24.]]\n",
    "  [[ 1.  1.  0.]\n",
    "   [ 0.  1. 12.]\n",
    "   [ 0.  0.  0.]]\n",
    "  [[ 3.  0.  2.]\n",
    "   [ 0.  0.  0.]\n",
    "   [30.  1. 44.]]\n",
    "  [[ 0.  0.  0.]\n",
    "   [ 0.  0.  0.]\n",
    "   [ 1.  0.  1.]]\n",
    "  [[ 1.  0.  0.]\n",
    "   [ 0.  3. 20.]\n",
    "   [51.  1. 46.]]\n",
    "  [[ 0.  0.  0.]\n",
    "   [ 0.  0. 52.]\n",
    "   [88.  0. 71.]]]]\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Backward Pass:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Gradienten definieren\n",
    "y_grad = torch.ones(y.shape)\n",
    "\n",
    "# Backpass durchfuehren\n",
    "y.backward(y_grad)\n",
    "\n",
    "# Ergebnis ueberpruefen\n",
    "interactive_check('resnet_backward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "    <br>\n",
    "    <i>Augaben bei korrekter Implementierung:</i>\n",
    "    <br>\n",
    "    <code style=\"padding: 0\">\n",
    "z.grad:\n",
    "[[[[1. 1. 0.]\n",
    "   [0. 0. 1.]\n",
    "   [0. 1. 0.]]\n",
    "  [[1. 0. 0.]\n",
    "   [1. 1. 0.]\n",
    "   [1. 1. 1.]]\n",
    "  [[1. 0. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [1. 1. 1.]]\n",
    "  [[1. 1. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [0. 0. 0.]]\n",
    "  [[1. 0. 1.]\n",
    "   [0. 0. 0.]\n",
    "   [1. 1. 1.]]\n",
    "  [[0. 0. 0.]\n",
    "   [0. 0. 0.]\n",
    "   [1. 0. 1.]]\n",
    "  [[1. 0. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [1. 1. 1.]]\n",
    "  [[0. 0. 0.]\n",
    "   [0. 0. 1.]\n",
    "   [1. 0. 1.]]]]\n",
    "res.grad:\n",
    "[[[[1. 1. 0.]\n",
    "   [0. 0. 1.]\n",
    "   [0. 1. 0.]]\n",
    "  [[1. 0. 0.]\n",
    "   [1. 1. 0.]\n",
    "   [1. 1. 1.]]\n",
    "  [[1. 0. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [1. 1. 1.]]\n",
    "  [[1. 1. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [0. 0. 0.]]\n",
    "  [[1. 0. 1.]\n",
    "   [0. 0. 0.]\n",
    "   [1. 1. 1.]]\n",
    "  [[0. 0. 0.]\n",
    "   [0. 0. 0.]\n",
    "   [1. 0. 1.]]\n",
    "  [[1. 0. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [1. 1. 1.]]\n",
    "  [[0. 0. 0.]\n",
    "   [0. 0. 1.]\n",
    "   [1. 0. 1.]]]]\n",
    "x_res.grad:\n",
    "[[[[   0.   13.    0.]\n",
    "   [  30.  -78.   39.]\n",
    "   [  51.  104.   38.]]\n",
    "  [[   0.   26.    0.]\n",
    "   [  60.    0.  138.]\n",
    "   [  42.    0.   16.]]\n",
    "  [[   0.  -26.    0.]\n",
    "   [ -60.   39. -123.]\n",
    "   [ -57.  -52.  -31.]]\n",
    "  [[   0.    0.    0.]\n",
    "   [   0.  -39.  -15.]\n",
    "   [  15.   52.   15.]]\n",
    "  [[   0.   13.    0.]\n",
    "   [  30.   39.   84.]\n",
    "   [   6.  -52.   -7.]]\n",
    "  [[   0.   13.    0.]\n",
    "   [  30.    0.   69.]\n",
    "   [  21.    0.    8.]]\n",
    "  [[   0.  -39.    0.]\n",
    "   [ -90.   39. -192.]\n",
    "   [ -78.  -52.  -39.]]\n",
    "  [[   0.   26.    0.]\n",
    "   [  60.   39.  153.]\n",
    "   [  27.  -52.    1.]]]]\n",
    "x_skip.grad:\n",
    "[[[[1. 1. 0.]\n",
    "   [0. 0. 1.]\n",
    "   [0. 1. 0.]]\n",
    "  [[1. 0. 0.]\n",
    "   [1. 1. 0.]\n",
    "   [1. 1. 1.]]\n",
    "  [[1. 0. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [1. 1. 1.]]\n",
    "  [[1. 1. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [0. 0. 0.]]\n",
    "  [[1. 0. 1.]\n",
    "   [0. 0. 0.]\n",
    "   [1. 1. 1.]]\n",
    "  [[0. 0. 0.]\n",
    "   [0. 0. 0.]\n",
    "   [1. 0. 1.]]\n",
    "  [[1. 0. 0.]\n",
    "   [0. 1. 1.]\n",
    "   [1. 1. 1.]]\n",
    "  [[0. 0. 0.]\n",
    "   [0. 0. 1.]\n",
    "   [1. 0. 1.]]]]\n",
    "x.grad:\n",
    "[[[[   1.   14.    0.]\n",
    "   [  30.  -78.   40.]\n",
    "   [  51.  105.   38.]]\n",
    "  [[   1.   26.    0.]\n",
    "   [  61.    1.  138.]\n",
    "   [  43.    1.   17.]]\n",
    "  [[   1.  -26.    0.]\n",
    "   [ -60.   40. -122.]\n",
    "   [ -56.  -51.  -30.]]\n",
    "  [[   1.    1.    0.]\n",
    "   [   0.  -38.  -14.]\n",
    "   [  15.   52.   15.]]\n",
    "  [[   1.   13.    1.]\n",
    "   [  30.   39.   84.]\n",
    "   [   7.  -51.   -6.]]\n",
    "  [[   0.   13.    0.]\n",
    "   [  30.    0.   69.]\n",
    "   [  22.    0.    9.]]\n",
    "  [[   1.  -39.    0.]\n",
    "   [ -90.   40. -191.]\n",
    "   [ -77.  -51.  -38.]]\n",
    "  [[   0.   26.    0.]\n",
    "   [  60.   39.  154.]\n",
    "   [  28.  -52.    2.]]]]\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$_{_\\text{Created for Deep Learning for Computer Vision (DL4CV)}}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}